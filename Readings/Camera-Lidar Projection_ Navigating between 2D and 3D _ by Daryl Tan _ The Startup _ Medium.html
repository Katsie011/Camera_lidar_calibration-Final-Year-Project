<!DOCTYPE html>
<!-- saved from url=(0089)https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/branch-latest.min.js"></script><script async="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/analytics.js"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><script defer="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/16180790160.js"></script><title>Camera-Lidar Projection: Navigating between 2D and 3D | by Daryl Tan | The Startup | Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-10-17T01:09:55.489Z"><meta data-rh="true" name="title" content="Camera-Lidar Projection: Navigating between 2D and 3D | by Daryl Tan | The Startup | Medium"><meta data-rh="true" property="og:title" content="Camera-Lidar Projection: Navigating between 2D and 3D"><meta data-rh="true" property="twitter:title" content="Camera-Lidar Projection: Navigating between 2D and 3D"><meta data-rh="true" name="twitter:site" content="@thestartup_"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/911c78167a94"><meta data-rh="true" property="al:android:url" content="medium://p/911c78167a94"><meta data-rh="true" property="al:ios:url" content="medium://p/911c78167a94"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a means for detection and localisation of other objects, giving…"><meta data-rh="true" property="og:description" content="Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a…"><meta data-rh="true" property="twitter:description" content="Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a…"><meta data-rh="true" property="og:url" content="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94"><meta data-rh="true" property="al:web:url" content="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*-WFfHL24zz_mOZM7_blSOQ.png"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*-WFfHL24zz_mOZM7_blSOQ.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://medium.com/@daryl.tanyj"><meta data-rh="true" name="author" content="Daryl Tan"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="8 min read"><meta data-rh="true" name="parsely-post-id" content="911c78167a94"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@daryl.tanyj"><link data-rh="true" rel="canonical" href="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/911c78167a94"><link data-rh="true" rel="icon" href="https://miro.medium.com/1*m-R_BkNf1Qjr1YbyOIJY2w.png"><script data-dapp-detection="">
(function() {
  let alreadyInsertedMetaTag = false

  function __insertDappDetected() {
    if (!alreadyInsertedMetaTag) {
      const meta = document.createElement('meta')
      meta.name = 'dapp-detected'
      document.head.appendChild(meta)
      alreadyInsertedMetaTag = true
    }
  }

  if (window.hasOwnProperty('web3')) {
    // Note a closure can't be used for this var because some sites like
    // www.wnyc.org do a second script execution via eval for some reason.
    window.__disableDappDetectionInsertion = true
    // Likely oldWeb3 is undefined and it has a property only because
    // we defined it. Some sites like wnyc.org are evaling all scripts
    // that exist again, so this is protection against multiple calls.
    if (window.web3 === undefined) {
      return
    }
    __insertDappDetected()
  } else {
    var oldWeb3 = window.web3
    Object.defineProperty(window, 'web3', {
      configurable: true,
      set: function (val) {
        if (!window.__disableDappDetectionInsertion)
          __insertDappDetected()
        oldWeb3 = val
      },
      get: function () {
        if (!window.__disableDappDetectionInsertion)
          __insertDappDetected()
        return oldWeb3
      }
    })
  }
})()</script><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="589" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style data-fela-type="KEYFRAME" type="text/css">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:35px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{position:absolute}.u{top:0}.v{left:0}.w{right:0}.x{z-index:500}.y{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ah{max-width:1192px}.ai{min-width:0}.aj{width:100%}.ak{height:65px}.an{flex:1 0 auto}.ao{height:25px}.ap{fill:rgba(25, 25, 25, 1)}.aq{flex:0 0 auto}.ar{visibility:hidden}.as{margin-left:16px}.at{color:rgba(132, 133, 133, 1)}.au{fill:rgba(132, 133, 133, 1)}.av{font-size:inherit}.aw{border:inherit}.ax{font-family:inherit}.ay{letter-spacing:inherit}.az{font-weight:inherit}.ba{padding:0}.bb{margin:0}.bc:hover{cursor:pointer}.bd:hover{color:rgba(113, 114, 114, 1)}.be:hover{fill:rgba(113, 114, 114, 1)}.bf:disabled{cursor:default}.bg:disabled{color:rgba(26, 137, 23, 0.3)}.bh:disabled{fill:rgba(26, 137, 23, 0.3)}.bi{border-top:none}.bj{background-color:rgba(249, 249, 249, 1)}.bl{height:54px}.bm{overflow:hidden}.bn{margin-right:40px}.bo{height:36px}.bp{width:211px}.bq{overflow:auto}.br{flex:0 1 auto}.bs{list-style-type:none}.bt{line-height:40px}.bu{white-space:nowrap}.bv{overflow-x:auto}.bw{align-items:flex-start}.bx{margin-top:20px}.by{padding-top:20px}.bz{height:80px}.ca{height:20px}.cb{margin-right:15px}.cc{margin-left:15px}.cd:first-child{margin-left:0}.ce{min-width:1px}.cf{background-color:rgba(131, 132, 132, 1)}.cg{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.ch{font-size:13px}.ci{line-height:20px}.cj{color:rgba(60, 62, 62, 1)}.ck{text-transform:uppercase}.cl{letter-spacing:1px}.cm{color:inherit}.cn{fill:inherit}.co:hover{color:rgba(46, 47, 48, 1)}.cp:hover{fill:rgba(46, 47, 48, 1)}.cq:disabled{color:rgba(109, 110, 110, 1)}.cr:disabled{fill:rgba(109, 110, 110, 1)}.cs{margin-bottom:0px}.ct{margin-top:0px}.cu{height:119px}.cx{padding-left:24px}.cy{padding-right:24px}.cz{margin-left:auto}.da{margin-right:auto}.db{max-width:728px}.dc{box-sizing:border-box}.dd{top:calc(100vh + 100px)}.de{bottom:calc(100vh + 100px)}.df{width:10px}.dg{pointer-events:none}.dh{word-break:break-word}.di{word-wrap:break-word}.dj:after{display:block}.dk:after{content:""}.dl:after{clear:both}.dm{max-width:680px}.dn{line-height:1.23}.do{letter-spacing:0}.dp{font-style:normal}.dq{font-family:fell, Georgia, Cambria, "Times New Roman", Times, serif}.el{margin-bottom:-0.27em}.em{color:rgba(41, 41, 41, 1)}.en{margin-top:32px}.eo{justify-content:space-between}.es{position:relative}.et{width:48px}.eu{height:48px}.ev{fill:rgba(26, 137, 23, 1)}.ew{flex-direction:row}.ex{width:calc(100% + 25px)}.ey{height:calc(100% + 25px)}.ez{top:50%}.fa{left:50%}.fb{transform:translateX(-50%) translateY(-50%)}.fc{border-radius:50%}.fd{margin-left:12px}.fe{font-size:14px}.ff{margin-bottom:2px}.fh{max-height:20px}.fi{text-overflow:ellipsis}.fj{display:-webkit-box}.fk{-webkit-line-clamp:1}.fl{-webkit-box-orient:vertical}.fn:hover{text-decoration:underline}.fo:disabled{color:rgba(117, 117, 117, 1)}.fp:disabled{fill:rgba(117, 117, 117, 1)}.fq{margin-left:8px}.fr{padding:0px 8px 1px}.fs{background:0}.ft{border-color:rgba(117, 117, 117, 1)}.fu:hover{color:rgba(8, 8, 8, 1)}.fv:hover{fill:rgba(8, 8, 8, 1)}.fw:hover{border-color:rgba(41, 41, 41, 1)}.fx:disabled{cursor:inherit}.fy:disabled{opacity:0.3}.fz:disabled:hover{color:rgba(41, 41, 41, 1)}.ga:disabled:hover{fill:rgba(41, 41, 41, 1)}.gb:disabled:hover{border-color:rgba(117, 117, 117, 1)}.gc{border-radius:4px}.gd{border-width:1px}.ge{border-style:solid}.gf{display:inline-block}.gg{text-decoration:none}.gh{color:rgba(117, 117, 117, 1)}.gi{align-items:flex-end}.gq{padding-right:6px}.gr:hover{color:rgba(25, 25, 25, 1)}.gs:hover{fill:rgba(25, 25, 25, 1)}.gt{fill:rgba(117, 117, 117, 1)}.gu{margin-right:8px}.gv{margin-right:-6px}.gw{clear:both}.hc{opacity:0}.hd{transition:opacity 100ms 400ms}.he{height:100%}.hf{will-change:transform}.hg{transform:translateZ(0)}.hh{margin:auto}.hi{background-color:rgba(242, 242, 242, 1)}.hj{padding-bottom:75.01951600312256%}.hk{height:0}.hl{filter:blur(20px)}.hm{transform:scale(1.1)}.hn{visibility:visible}.ho{margin-top:10px}.hp{text-align:center}.hs{text-decoration:underline}.ht{line-height:1.58}.hu{letter-spacing:-0.004em}.hv{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.iq{margin-bottom:-0.46em}.ir{line-height:1.18}.is{letter-spacing:-0.022em}.it{font-weight:500}.jo{margin-bottom:-0.31em}.ju{max-width:517px}.jv{padding-bottom:56.67311411992263%}.jw{font-weight:700}.jx{padding:2px 4px}.jy{font-size:75%}.jz> strong{font-family:inherit}.ka{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.kb{line-height:1.12}.kp{margin-bottom:-0.28em}.kq{max-width:391px}.kr{padding-bottom:83.37595907928389%}.ks{list-style-type:disc}.kt{margin-left:30px}.ku{padding-left:0px}.la{max-width:2600px}.lb{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.lc{cursor:zoom-in}.ld{z-index:auto}.le{padding-bottom:44.65384615384615%}.lf{max-width:356px}.lg{padding-bottom:33.146067415730336%}.lh{padding:20px}.li{background:rgba(242, 242, 242, 1)}.lj{font-size:16px}.lk{margin-top:-0.09em}.ll{margin-bottom:-0.09em}.lm{white-space:pre-wrap}.ln{max-width:406px}.lo{padding-bottom:51.970443349753694%}.lp{font-style:italic}.lv{max-width:914px}.lw{padding-bottom:61.159737417943106%}.lx{max-width:1242px}.ly{padding-bottom:30.193236714975846%}.lz{max-width:2804px}.ma{padding-bottom:44.36519258202568%}.mb{box-shadow:inset 3px 0 0 0 rgba(41, 41, 41, 1)}.mc{padding-left:23px}.md{margin-left:-20px}.me{margin-bottom:14px}.mf{padding-top:24px}.mg{padding-bottom:10px}.mh{background-color:rgba(8, 8, 8, 1)}.mi{height:3px}.mj{width:3px}.mk{margin-right:20px}.ml{box-shadow:inset 0 0 0 1px rgba(230, 230, 230, 1)}.mm{padding:0px}.mn{padding:16px 20px}.mo{flex-direction:column}.mp{flex:1 1 auto}.mr{font-size:20px}.ms{line-height:28px}.mt{max-height:56px}.mu{-webkit-line-clamp:2}.mv{margin-top:8px}.mw{max-height:40px}.mx{margin-top:12px}.my{width:160px}.mz{background-image:url(https://miro.medium.com/max/320/0*E157DD0A14RKI9Yw)}.na{background-origin:border-box}.nb{background-size:cover}.nc{height:167px}.nd{background-position:50% 50%}.ne{max-width:100%}.nf{background-image:url(https://miro.medium.com/max/320/1*T2HqDxVSXO3xLjm3U-zkkA.jpeg)}.ng{will-change:opacity}.nh{position:fixed}.ni{width:188px}.nj{transform:translateX(406px)}.nk{top:calc(65px + 54px + 14px)}.nn{top:159px}.np{width:131px}.nq{padding-bottom:28px}.nr{border-bottom:1px solid rgba(230, 230, 230, 1)}.ns{padding-bottom:20px}.nt{padding-top:2px}.nu{max-height:120px}.nv{-webkit-line-clamp:6}.nw{padding:4px 12px 6px}.nx{border-color:rgba(132, 133, 133, 1)}.ny:hover{border-color:rgba(113, 114, 114, 1)}.nz:disabled:hover{color:rgba(132, 133, 133, 1)}.oa:disabled:hover{fill:rgba(132, 133, 133, 1)}.ob:disabled:hover{border-color:rgba(132, 133, 133, 1)}.oc{padding-top:28px}.od{margin-bottom:19px}.oe{margin-left:-3px}.ok{outline:0}.ol{border:0}.om{user-select:none}.on{cursor:pointer}.oo> svg{pointer-events:none}.op:active{border-style:none}.oq{-webkit-user-select:none}.or:focus{fill:rgba(117, 117, 117, 1)}.os:hover{fill:rgba(117, 117, 117, 1)}.pa button{text-align:left}.pb{opacity:0.4}.pc{cursor:not-allowed}.pd{padding-right:4px}.pm{margin-top:40px}.pn{flex-wrap:wrap}.po{margin-top:25px}.pp{margin-bottom:8px}.pq{line-height:22px}.pr{border-radius:3px}.ps{padding:5px 10px}.pt{max-width:155px}.px{top:1px}.ql{margin-left:-1px}.qm{margin-left:-4px}.qu{padding-right:8px}.qv{padding-top:32px}.qw{border-top:1px solid rgba(230, 230, 230, 1)}.qx{margin-bottom:25px}.qz{margin-bottom:32px}.ra{min-height:80px}.rf{width:80px}.rg{padding-left:102px}.ri{line-height:18px}.rj{letter-spacing:0.077em}.rk{margin-bottom:6px}.rl{font-size:22px}.rm{max-width:555px}.rn{max-width:450px}.ro{line-height:24px}.rp{display:none}.rr{max-width:550px}.rs{margin-top:5px}.rt{width:40px}.ru{height:40px}.rv{font-size:12px}.rw{line-height:16px}.rx{letter-spacing:0.083em}.ry{padding-top:8px}.rz{padding-top:25px}.sb{background:rgba(255, 255, 255, 1)}.sc{margin-bottom:40px}.sd{margin-top:24px}.se{padding-bottom:16px}.sf{margin-bottom:24px}.tr{flex-grow:0}.ts{padding-bottom:24px}.tt{max-width:500px}.tx{padding-bottom:8px}.uk{padding-bottom:100%}.uv{padding:60px 0}.uw{background-color:rgba(0, 0, 0, 0.9)}.uy{padding-bottom:48px}.uz{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.va{margin:0 -12px}.vb{margin:0 12px}.vc{flex:1 1 0}.vd:hover{color:rgba(255, 255, 255, 0.99)}.ve:hover{fill:rgba(255, 255, 255, 0.99)}.vf:disabled{color:rgba(255, 255, 255, 0.7)}.vg:disabled{fill:rgba(255, 255, 255, 0.7)}.vh{color:rgba(255, 255, 255, 0.98)}.vi{color:rgba(255, 255, 255, 0.7)}.vj{fill:rgba(255, 255, 255, 1)}.vk{height:22px}.vl{width:200px}.vr{margin-right:16px}.vs{background-image:url(https://miro.medium.com/max/160/0*E157DD0A14RKI9Yw)}.vt{background-image:url(https://miro.medium.com/max/160/1*T2HqDxVSXO3xLjm3U-zkkA.jpeg)}.vu{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.ag{margin:0 64px}.eh{font-size:48px}.ei{margin-top:0.55em}.ej{line-height:60px}.ek{letter-spacing:-0.011em}.gp{margin-left:30px}.hb{margin-top:56px}.im{font-size:21px}.in{margin-top:2em}.io{line-height:32px}.ip{letter-spacing:-0.003em}.jk{font-size:22px}.jl{margin-top:1.72em}.jm{line-height:28px}.jn{letter-spacing:0}.jt{margin-top:0.86em}.km{font-size:30px}.kn{margin-top:1.95em}.ko{line-height:36px}.kz{margin-top:1.05em}.lu{margin-top:1.91em}.oj{margin-right:5px}.oz{margin-top:5px}.pl{padding-left:6px}.pz{display:inline-block}.qe{margin-left:7px}.qf{margin-top:8px}.qk{width:25px}.qs{padding-left:7px}.qt{top:3px}.su{width:calc(100% + 32px)}.sv{margin-left:-16px}.sw{margin-right:-16px}.tn{padding-left:16px}.to{padding-right:16px}.tp{flex-basis:25%}.tq{max-width:25%}.ug{font-size:16px}.uh{line-height:20px}.ut{min-width:70px}.uu{min-height:70px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.go{margin-left:30px}.hq{margin-left:auto}.hr{text-align:center}.oi{margin-right:5px}.oy{margin-top:5px}.pk{padding-left:6px}.py{display:inline-block}.qc{margin-left:7px}.qd{margin-top:8px}.qj{width:25px}.qq{padding-left:7px}.qr{top:3px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.gn{margin-left:30px}.oh{margin-right:5px}.ox{margin-top:5px}.pi{padding-left:6px}.pj{top:3px}.pw{display:inline-block}.qa{margin-left:7px}.qb{margin-top:8px}.qi{width:15px}.qp{padding-left:3px}.tw{margin-right:16px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.al{height:56px}.am{display:flex}.bk{display:block}.cv{margin-bottom:0px}.cw{height:110px}.eq{margin-top:32px}.er{flex-direction:column-reverse}.gl{margin-bottom:30px}.gm{margin-left:0px}.mq{padding:10px 12px 10px}.og{margin-left:8px}.ov{margin-top:2px}.ow{margin-right:8px}.pg{padding-left:6px}.ph{top:3px}.pv{display:inline-block}.qh{width:15px}.qo{padding-left:3px}.qy{padding-top:0}.rb{margin-bottom:24px}.rc{align-items:center}.rd{width:102px}.re{position:relative}.rh{padding-left:0}.rq{margin-top:24px}.sa{border-top:none}.sg{padding-bottom:12px}.sh{margin-top:16px}.tv{margin-right:16px}.ui{margin-left:16px}.uj{margin-right:0px}.ux{padding:32px 0}.vm{width:140px}.vn{margin-bottom:16px}.vo{margin-top:30px}.vp{width:100%}.vq{flex-direction:row}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.ab{margin:0 24px}.dr{font-size:34px}.ds{margin-top:0.56em}.dt{line-height:42px}.du{letter-spacing:-0.016em}.ep{margin-top:32px}.fg{margin-bottom:0px}.gj{margin-bottom:30px}.gk{margin-left:0px}.gx{margin-top:40px}.hw{font-size:18px}.hx{margin-top:1.56em}.hy{line-height:28px}.hz{letter-spacing:-0.003em}.iu{font-size:20px}.iv{margin-top:1.23em}.iw{line-height:24px}.ix{letter-spacing:0}.jp{margin-top:0.67em}.kc{font-size:22px}.kd{margin-top:1.2em}.kv{margin-top:1.34em}.lq{margin-top:1.41em}.of{margin-left:8px}.ot{margin-top:2px}.ou{margin-right:8px}.pe{padding-left:6px}.pf{top:3px}.pu{display:inline-block}.qg{width:15px}.qn{padding-left:3px}.si{width:calc(100% + 24px)}.sj{margin-left:-12px}.sk{margin-right:-12px}.sx{padding-left:12px}.sy{padding-right:12px}.sz{flex-basis:100%}.ta{max-width:100%}.tu{margin-right:16px}.ty{font-size:16px}.tz{line-height:20px}.ul{min-width:48px}.um{min-height:48px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.af{margin:0 64px}.ed{font-size:48px}.ee{margin-top:0.55em}.ef{line-height:60px}.eg{letter-spacing:-0.011em}.ha{margin-top:56px}.ii{font-size:21px}.ij{margin-top:2em}.ik{line-height:32px}.il{letter-spacing:-0.003em}.jg{font-size:22px}.jh{margin-top:1.72em}.ji{line-height:28px}.jj{letter-spacing:0}.js{margin-top:0.86em}.kj{font-size:30px}.kk{margin-top:1.95em}.kl{line-height:36px}.ky{margin-top:1.05em}.lt{margin-top:1.91em}.sr{width:calc(100% + 32px)}.ss{margin-left:-16px}.st{margin-right:-16px}.tj{padding-left:16px}.tk{padding-right:16px}.tl{flex-basis:25%}.tm{max-width:25%}.ue{font-size:16px}.uf{line-height:20px}.ur{min-width:70px}.us{min-height:70px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ae{margin:0 48px}.dz{font-size:48px}.ea{margin-top:0.55em}.eb{line-height:60px}.ec{letter-spacing:-0.011em}.gz{margin-top:56px}.ie{font-size:21px}.if{margin-top:2em}.ig{line-height:32px}.ih{letter-spacing:-0.003em}.jc{font-size:22px}.jd{margin-top:1.72em}.je{line-height:28px}.jf{letter-spacing:0}.jr{margin-top:0.86em}.kg{font-size:30px}.kh{margin-top:1.95em}.ki{line-height:36px}.kx{margin-top:1.05em}.ls{margin-top:1.91em}.so{width:calc(100% + 28px)}.sp{margin-left:-14px}.sq{margin-right:-14px}.tf{padding-left:14px}.tg{padding-right:14px}.th{flex-basis:50%}.ti{max-width:50%}.uc{font-size:16px}.ud{line-height:20px}.up{min-width:48px}.uq{min-height:48px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ac{margin:0 24px}.dv{font-size:34px}.dw{margin-top:0.56em}.dx{line-height:42px}.dy{letter-spacing:-0.016em}.gy{margin-top:40px}.ia{font-size:18px}.ib{margin-top:1.56em}.ic{line-height:28px}.id{letter-spacing:-0.003em}.iy{font-size:20px}.iz{margin-top:1.23em}.ja{line-height:24px}.jb{letter-spacing:0}.jq{margin-top:0.67em}.ke{font-size:22px}.kf{margin-top:1.2em}.kw{margin-top:1.34em}.lr{margin-top:1.41em}.sl{width:calc(100% + 24px)}.sm{margin-left:-12px}.sn{margin-right:-12px}.tb{padding-left:12px}.tc{padding-right:12px}.td{flex-basis:100%}.te{max-width:100%}.ua{font-size:16px}.ub{line-height:20px}.un{min-width:48px}.uo{min-height:48px}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="print">.z{display:none}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.fm{max-height:none}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nl{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 1230px)">.nm{display:none}</style><style type="text/css" data-fela-rehydration="589" data-fela-type="RULE" media="all and (max-width: 1198px)">.no{display:none}</style><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*-WFfHL24zz_mOZM7_blSOQ.png"],"url":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94","dateCreated":"2020-01-30T16:31:49.422Z","datePublished":"2020-01-30T16:31:49.422Z","dateModified":"2020-10-17T01:10:06.520Z","headline":"Camera-Lidar Projection: Navigating between 2D and 3D","name":"Camera-Lidar Projection: Navigating between 2D and 3D","description":"Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a means for detection and localisation of other objects, giving…","identifier":"911c78167a94","keywords":["Lite:true","Tag:Machine Learning","Tag:Python","Tag:Computer Vision","Tag:Autonomous Vehicles","Tag:Robotics","Topic:Machine Learning","Publication:swlh","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_UGC","LayerCake:3"],"author":{"@type":"Person","name":"Daryl Tan","url":"https:\u002F\u002Fmedium.com\u002F@daryl.tanyj"},"creator":["Daryl Tan"],"publisher":{"@type":"Organization","name":"The Startup","url":"https:\u002F\u002Fmedium.com\u002Fswlh","logo":{"@type":"ImageObject","width":350,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F350\u002F1*IOJrKVmLnRcFz3E_KrrN_Q.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94","isAccessibleForFree":"False","hasPart":{"@type":"WebPageElement","isAccessibleForFree":"False","cssSelector":".meteredContent"}}</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><style id="googleidentityservice_button_styles">.qJTHM{-webkit-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:'Roboto-Regular',arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{word-break:break-all}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-uaxL4e{-webkit-border-radius:10px;border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf,.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}#progress-bar>div:nth-child(1){background-color:#1a73e8}#progress-bar>div:nth-child(2),#progress-bar>div:nth-child(3){background-image:linear-gradient(to right,rgba(255,255,255,0.7),rgba(255,255,255,0.7)),linear-gradient(to right,#1a73e8,#1a73e8)}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-webkit-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:'Google Sans',arial,sans-serif;font-size:14px;height:40px;letter-spacing:.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{-webkit-border-radius:20px;border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{-webkit-border-radius:16px;border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{-webkit-border-radius:10px;border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:3px;border-top-left-radius:3px;-webkit-border-bottom-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;justify-content:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:3px;border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:14px;border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:8px;border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;-webkit-flex-direction:row;flex-direction:row;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;flex-grow:1;font-family:'Google Sans',arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{-webkit-box-shadow:none;box-shadow:none;border-color:#d2e3fc;outline:none}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.04)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{-webkit-border-radius:50%;border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:'Roboto';font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:0;border-top-left-radius:0;-webkit-border-bottom-left-radius:0;border-bottom-left-radius:0;-webkit-border-top-right-radius:3px;border-top-right-radius:3px;-webkit-border-bottom-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{-webkit-border-radius:4px;border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}
/*# sourceURL=/_/gsi/_/ss/k=gsi.gsi.MBblKLBqS1w.L.W.O/am=CQ/d=1/ct=zgms/rs=AF0KOtUOR4biOQcucuPRqSV-3cYVNt8nHg/m=gis_client_button_style */</style><link id="googleidentityservice" type="text/css" media="all" rel="stylesheet" href="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/style"><script charset="utf-8" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_CollectionNewShortformEditor_CollectionPostShortformEditor_responses.editor.b368c811.chunk.js"></script><script charset="utf-8" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/responses.editor.ccfda019.chunk.js"></script></head><body data-new-gr-c-s-loaded="true"><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="s t u v w c x y z"><div><div class="s c"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="ak n o al am"><div class="n o an x"><a rel="noopener" href="https://medium.com/?source=post_page-----911c78167a94--------------------------------"><svg viewBox="0 0 1043.63 592.71" class="ao ap"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div><div class="s aq x"><div class="n o"><div class="n o g"><div class="hn" id="lo-post-page-navbar-sign-in-link"><div class="as s"><span><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=--------------------------nav_reg-----------" class="at au av aw ax ay az ba bb bc bd be bf bg bh" rel="noopener">Sign in</a></span></div></div></div><div class="rp am rc"><div class="hn" id="lo-general-navbar-open-in-app-button"><div class="as rp bk"><span class="cg b fe ci gh"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F911c78167a94&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=--------------------------nav_reg-----------" class="at au av aw ax ay az ba bb bc bd be bf bg bh" rel="noopener nofollow">Open in app</a></span></div></div></div><div class="hn" id="lo-post-page-navbar-sign-in-button"><div class="as s"><span><button class="cg b fe ci at vv fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg">Get started</button></span></div></div></div></div></div></div></div></div><div class="bi s bj bk"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="bl bm n o"><div class="bn s aq"><a href="https://medium.com/swlh?source=post_page-----911c78167a94--------------------------------" rel="noopener"><div class="bo bp s"><img alt="The Startup" class="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_IOJrKVmLnRcFz3E_KrrN_Q.png" width="211" height="36"></div></a></div><div class="bq s br"><ul class="bs bb bt bu bv n bw g bx by bz"><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener" href="https://medium.com/swlh/a-call-for-great-stories-were-reimagining-the-startup-medium-s-largest-publication-with-680k-b06013ae1017?source=post_page-----911c78167a94--------------------------------">We’re Reimagining The Startup</a></span></li><span class="ca ce cf"></span><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://medium.com/curious?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Are you curious?</a></span></li></ul></div></div></div></div></div></div></nav><div class="cs ct cu s cv cw"></div><div class="s z"><div class="wr ws aj he nh wt wu on hc wv dg" aria-hidden="true"></div><div class="ww nh wx wy wk wr he dc bq wz xa we xb xc xd vp xe xf xg xh" aria-hidden="true"><div class="xi xj n o ew eo"><h2 class="cg it mr ro do em">Responses </h2><div class="n ew"><div class="s es xk"><div class="bb s es w"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" data-testid="close-button" aria-label="close"><svg width="25" height="25" viewBox="0 0 25 25" class="gt"><path d="M18.13 6.11l-5.61 5.61-5.6-5.61-.81.8 5.61 5.61-5.61 5.61.8.8 5.61-5.6 5.61 5.6.8-.8-5.6-5.6 5.6-5.62"></path></svg></button></div></div></div></div><div class="xl yh s"><div class="wy xy gc n mo xz ya yb"><div class="n mo"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=--------------------------respond_sidebar-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><div class="yi s"><h4 class="cg b fe ci gh">What are your thoughts?</h4></div></a></span><div class="n yc yd ye hc yf"><div class="yg"><button class="cg b fe ci em nw r fs ft fu fv fw bc fx fy fz ga gb gc gd ge dc gf gg">Cancel</button></div><button class="cg b fe ci yj nw vj yk yl ym yn bc fx fy yo yp gc gd ge dc gf gg" disabled="">Respond</button></div></div></div></div><div class="xw hp n mo p o lp xx"><h4 class="cg b lj ro gh">There are currently no responses for this story.</h4><h4 class="cg b lj ro gh">Be the first to respond.</h4></div></div></div><article class="meteredContent"><section class="cx cy cz da aj db dc s"><div class="hn" id="lo-highlight-meter-2-highlight-box"><div class="vw gc vx es vy"><div class="vz wa n eo wb"><h4 class="cg b lj ro em"><span class="hn" id="lo-highlight-meter-2-copy">You have <b>1</b> free member-only story left this month. </span><div class="wc bu"><span class="hn" id="lo-highlight-meter-2-link"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=-----911c78167a94---------------------metered_view_2-----------" class="cm cn av aw ax ay az ba bb bc bf fo fp hs" rel="noopener">Sign up for Medium and get an extra one</a></span></span></div></h4></div></div></div></section><span class="s"></span><div><div class="t v wh de df dg"></div><div class="cz da db es"><div class="s h g f e"><aside class="wk t u" style="width: 571.5px;"><div class="wn ne t wo bu aj"><h4 class="cg b ch ci gh"><span class="gf ne bu bm fi">Top highlight</span></h4></div></aside></div></div><section class="dh di dj dk dl"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div><h1 id="b14b" class="dn do dp dq b dr ds dt du dv dw dx dy dz ea eb ec ed ee ef eg eh ei ej ek el em">Camera-Lidar Projection: Navigating between 2D and 3D</h1><div class="en"><div class="n eo ep eq er"><div class="o n"><div><a rel="noopener" href="https://medium.com/@daryl.tanyj?source=post_page-----911c78167a94--------------------------------"><div class="es et eu"><div class="ev n ew o p t ex ey ez fa fb dg"><svg width="57" height="57" viewBox="0 0 57 57"><path fill-rule="evenodd" clip-rule="evenodd" d="M28.5 1.2A27.45 27.45 0 0 0 4.06 15.82L3 15.27A28.65 28.65 0 0 1 28.5 0C39.64 0 49.29 6.2 54 15.27l-1.06.55A27.45 27.45 0 0 0 28.5 1.2zM4.06 41.18A27.45 27.45 0 0 0 28.5 55.8a27.45 27.45 0 0 0 24.44-14.62l1.06.55A28.65 28.65 0 0 1 28.5 57 28.65 28.65 0 0 1 3 41.73l1.06-.55z"></path></svg></div><img alt="Daryl Tan" class="s fc eu et" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/2_HNVsBoEb2aYvPS_Mitihog.png" width="48" height="48"></div></a></div><div class="fd aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="ff n o fg"><span class="cg b fe ci bm fh fi fj fk fl fm em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@daryl.tanyj?source=post_page-----911c78167a94--------------------------------">Daryl Tan</a></span><div class="fq s aq h"><span><button class="cg b ch ci em fr r fs ft fu fv fw bc fx fy fz ga gb gc gd ge dc gf gg">Follow</button></span></div></div></span></div></div><span class="cg b fe ci gh"><span class="cg b fe ci bm fh fi fj fk fl fm gh"><div><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94?source=post_page-----911c78167a94--------------------------------">Jan 30</a> <!-- -->·<!-- --> <!-- -->8<!-- --> min read<span style="padding-left:4px"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top:-2px"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div><div class="n gi gj gk gl gm gn go gp z"><div class="n o"><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on twitter"><svg width="29" height="29" class="gt"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on linkedin"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="gt"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on facebook"><svg width="29" height="29" class="gt"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="gu s"><div class="gt"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_actions_header--------------------------bookmark_preview-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div><div class="gv s an"></div></div></div></div></div></div></div></div><div class="gw aj"><figure class="gx gy gz ha hb gw aj paragraph-image"><div class="hh s es hi"><div class="hj hk s"><div class="hc hd t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm ar wp" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_-WFfHL24zz_mOZM7_blSOQ.png" width="1281" height="961"></div><img alt="Image for post" class="we wf t u v he aj c" width="1281" height="961" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_-WFfHL24zz_mOZM7_blSOQ(1).png" srcset="https://miro.medium.com/max/276/1*-WFfHL24zz_mOZM7_blSOQ.png 276w, https://miro.medium.com/max/552/1*-WFfHL24zz_mOZM7_blSOQ.png 552w, https://miro.medium.com/max/640/1*-WFfHL24zz_mOZM7_blSOQ.png 640w, https://miro.medium.com/max/728/1*-WFfHL24zz_mOZM7_blSOQ.png 728w, https://miro.medium.com/max/816/1*-WFfHL24zz_mOZM7_blSOQ.png 816w, https://miro.medium.com/max/904/1*-WFfHL24zz_mOZM7_blSOQ.png 904w, https://miro.medium.com/max/992/1*-WFfHL24zz_mOZM7_blSOQ.png 992w, https://miro.medium.com/max/1080/1*-WFfHL24zz_mOZM7_blSOQ.png 1080w, https://miro.medium.com/max/1281/1*-WFfHL24zz_mOZM7_blSOQ.png 1281w" sizes="1281px"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/2562/1*-WFfHL24zz_mOZM7_blSOQ.png" width="1281" height="961" srcSet="https://miro.medium.com/max/552/1*-WFfHL24zz_mOZM7_blSOQ.png 276w, https://miro.medium.com/max/1104/1*-WFfHL24zz_mOZM7_blSOQ.png 552w, https://miro.medium.com/max/1280/1*-WFfHL24zz_mOZM7_blSOQ.png 640w, https://miro.medium.com/max/1456/1*-WFfHL24zz_mOZM7_blSOQ.png 728w, https://miro.medium.com/max/1632/1*-WFfHL24zz_mOZM7_blSOQ.png 816w, https://miro.medium.com/max/1808/1*-WFfHL24zz_mOZM7_blSOQ.png 904w, https://miro.medium.com/max/1984/1*-WFfHL24zz_mOZM7_blSOQ.png 992w, https://miro.medium.com/max/2160/1*-WFfHL24zz_mOZM7_blSOQ.png 1080w, https://miro.medium.com/max/2562/1*-WFfHL24zz_mOZM7_blSOQ.png 1281w" sizes="1281px"/></noscript></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Figure 1. Lidar points on image (<a href="https://robotcar-dataset.robots.ox.ac.uk/images/ProjectLaserIntoCamera.png" class="cm hs" rel="noopener nofollow">source</a>)</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="2782" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in <mark class="wl wm on">tandem </mark>and provide a means for detection and localisation of other objects, giving robots rich semantic information required for safe navigation. Many researchers have started exploring multi-modal approaches for precise 3D object detection. An interesting example would be an algorithm developed by Aptiv, PointPainting[1]</p><h2 id="42f6" class="ir is dp cg it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo em" data-selectable-paragraph=""><strong class="az">So why is this 2 sensor complimentary?</strong></h2><p id="2ee2" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">Camera outperforms LIDAR when it comes to capturing denser and richer representation. From fig 2, looking at the sparse point cloud alone, it is relatively difficult to correctly identify the black box as a pedestrian. However, paying attention to the RGB image, even with the person back facing, we could easily tell the object looks like a pedestrian. Besides that, other useful visual features that could be extracted include traffic light and road sign which LIDAR struggles.</p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="cz da ju"><div class="hh s es hi"><div class="jv hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_BrOLss3ODN_JGUG5rI-WBw.png" width="517" height="293"></div><img alt="Image for post" class="hc hd t u v he aj c" width="517" height="293"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/1034/1*BrOLss3ODN_JGUG5rI-WBw.png" width="517" height="293" srcSet="https://miro.medium.com/max/552/1*BrOLss3ODN_JGUG5rI-WBw.png 276w, https://miro.medium.com/max/1034/1*BrOLss3ODN_JGUG5rI-WBw.png 517w" sizes="517px"/></noscript></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 2. RGB &amp; Point cloud representation with pedestrian detection</figcaption></figure><p id="55d7" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">In contrast, lidar excels when it comes to extracting distance information. It is extremely difficult to measure distance using the camera in standard perspective view which I explained in my <a href="https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c" class="cm hs" rel="noopener">previous post</a>.</p><p id="0b48" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">By fusing information from both sensors, the idea is we could leverage the advantages of both sensors, overcoming individual limitations. Having multiple sensors on-board also allows for <strong class="hv jw">redundancy</strong>, which is a crucial element in safe autonomous driving in the event of sensor failure.</p><h2 id="447a" class="ir is dp cg it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo em" data-selectable-paragraph=""><strong class="az">Objective</strong></h2><p id="ac83" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">In this post, I would like to take a step further into how LIDAR and camera data can be simultaneously leveraged and fused to create a more enriching and accurate 3D scene of the environment. But if you need a quick guide on the two sensors, I would recommend this <a href="https://blogs.nvidia.com/blog/2019/04/15/how-does-a-self-driving-car-see/" class="cm hs" rel="noopener nofollow">post</a> ;) What you need to understand is LIDAR process data as 3D point clouds and camera as pixels points in 3D or pixels on a 2D plane.</p><p id="1edf" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">We will use <a href="http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" class="cm hs" rel="noopener nofollow">Kitti 3D object detection dataset </a>as a reference. Refer to the Kitti Dataset website or to the <a href="https://github.com/darylclimb/cvml_project/tree/master/projections/lidar_camera_projection" class="cm hs" rel="noopener nofollow">code on Github</a> under the folder <code class="hi jx jy jz ka b">data</code> to understand the data format.</p><p id="63c6" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">For the rest of this article, we will first need to discuss the problem set up with regards to sensor placement and go through the Kitti object detection dataset to understand the data structure. How the calibration is done to understand the calibration matrices. Next, go in detail on 3D-2D and 2D-3D projection mapping, and finally, show the different types of lidar-camera data representation visually. All <code class="hi jx jy jz ka b">inline</code> text format are either functions, variables or <a href="https://github.com/darylclimb/cvml_project/tree/master/projections/lidar_camera_projection" class="cm hs" rel="noopener nofollow">files in the code</a>.</p><h1 id="f07f" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">Sensor Setup, Calibration and Coordinate System (KITTI)</h1><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="cz da kq"><div class="hh s es hi"><div class="kr hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_wMibQFL4SsSKDUkoLgi-OQ.png" width="391" height="326"></div><img alt="Image for post" class="hc hd t u v he aj c" width="391" height="326"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/782/1*wMibQFL4SsSKDUkoLgi-OQ.png" width="391" height="326" srcSet="https://miro.medium.com/max/552/1*wMibQFL4SsSKDUkoLgi-OQ.png 276w, https://miro.medium.com/max/782/1*wMibQFL4SsSKDUkoLgi-OQ.png 391w" sizes="391px"/></noscript></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 3. Kitti ego vehicle sensor placement (facing left)</figcaption></figure><p id="9343" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Before we begin with our analysis, there is a need to know the relative position of the sensors during the data acquisition process. This is necessary information to perform any transformation between one coordinate frame to another. Note that each sensor has its own coordinate frame as shown in fig 3.</p><h2 id="21f3" class="ir is dp cg it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo em" data-selectable-paragraph=""><strong class="az">Hardware specification</strong></h2><p id="aa34" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">Kitti several sensors including LIDAR, grayscale camera, colour cameras and IMU onboard the vehicle. However, we will only focus on:</p><ul class=""><li id="f108" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph=""><strong class="hv jw">Cam 0</strong>: Grayscale camera, left camera of a stereo rig. This is the reference camera</li><li id="471c" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph=""><strong class="hv jw">Cam 2</strong>: RGB colour camera, left camera of a stereo rig</li><li id="9b55" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph=""><strong class="hv jw">Velo</strong>: 64 beams Velodyne laser scanner</li></ul><p id="4f8a" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">Coordinate System</strong>: Vehicle facing left, left-hand coordinate system (fig 3)</p><h2 id="2e32" class="ir is dp cg it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo em" data-selectable-paragraph=""><strong class="az">What data do we have?</strong></h2><p id="d39d" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">Refer to <code class="hi jx jy jz ka b">data/readme.txt</code> for more details.</p><p id="37e5" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">Lidar point cloud </strong><code class="hi jx jy jz ka b"><strong class="hv jw">fileid.bin</strong></code><strong class="hv jw"> : </strong>2D array with shape <code class="hi jx jy jz ka b">[num_points, 4]</code> Each point encodes XYZ + reflectance.</p><p id="da9e" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">Object instance </strong><code class="hi jx jy jz ka b"><strong class="hv jw">fileid_label.txt</strong></code><strong class="hv jw"> : </strong>For each row, the annotation of each object is provided with 15 columns representing certain metadata and 3D box properties in <strong class="hv jw">camera coordinates</strong>:</p><p id="61ee" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><code class="hi jx jy jz ka b">type | truncation | visibility | observation angle | xmin | ymin |xmax | ymax | height | width | length | tx | ty | tz | roty</code></p><p id="231d" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Some instances <code class="hi jx jy jz ka b">type</code>are marked as ‘DontCare’, indicating they are not labelled.</p><p id="be62" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">RGB image </strong><code class="hi jx jy jz ka b"><strong class="hv jw">fileid_image.png</strong></code><strong class="hv jw"> : </strong>Image from camera 2</p><h2 id="bfc6" class="ir is dp cg it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo em" data-selectable-paragraph=""><strong class="az">Calibration Parameters</strong></h2><p id="734f" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph=""><code class="hi jx jy jz ka b"><strong class="hv jw">fileid_calib.txt</strong></code></p><p id="9a77" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">The calibration parameters are stored in row-major order. It contains the 3x4 projection matrix parameters which describe the mapping of 3D points in the world to 2D points in an image.</p><p id="c5e4" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">The calibration process is explained in [2]. Important things to take note is calibration is done with <code class="hi jx jy jz ka b">cam0</code> as the reference sensor. The laser scanner is registered with respect to the reference camera coordinate system.</p><p id="2e0f" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Rectification <code class="hi jx jy jz ka b">R_ref2rect</code>has also been considered during calibration to correct for planar alignment between cameras.</p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="lb lc es ld aj"><div class="cz da la"><div class="hh s es hi"><div class="le hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/0_rRWRXHIHP2YvrUYU.jpg" width="2600" height="1161"></div><img alt="Image for post" class="hc hd t u v he aj c" width="2600" height="1161"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/5200/0*rRWRXHIHP2YvrUYU.jpg" width="2600" height="1161" srcSet="https://miro.medium.com/max/552/0*rRWRXHIHP2YvrUYU.jpg 276w, https://miro.medium.com/max/1104/0*rRWRXHIHP2YvrUYU.jpg 552w, https://miro.medium.com/max/1280/0*rRWRXHIHP2YvrUYU.jpg 640w, https://miro.medium.com/max/1400/0*rRWRXHIHP2YvrUYU.jpg 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph=""><a href="https://en.wikipedia.org/wiki/Image_rectification" class="cm hs" rel="noopener nofollow">Rectification</a></figcaption></figure><p id="2036" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">It contains the following information:</p><ul class=""><li id="1667" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph=""><code class="hi jx jy jz ka b">P_rect[i]</code>: projective transformation from rectified reference camera frame to <code class="hi jx jy jz ka b">cam[i]</code> . Note that bx[i] denotes the baseline with respect to the reference camera 0.</li></ul><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="cz da lf"><div class="hh s es hi"><div class="lg hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_xhwMXO8ToFs8Ej7YBEjHIQ.png" width="356" height="118"></div><img alt="Image for post" class="hc hd t u v he aj c" width="356" height="118"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/712/1*xhwMXO8ToFs8Ej7YBEjHIQ.png" width="356" height="118" srcSet="https://miro.medium.com/max/552/1*xhwMXO8ToFs8Ej7YBEjHIQ.png 276w, https://miro.medium.com/max/712/1*xhwMXO8ToFs8Ej7YBEjHIQ.png 356w" sizes="356px"/></noscript></div></div></div></figure><ul class=""><li id="bd67" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph=""><code class="hi jx jy jz ka b">R0_rect</code> : rotation to account for rectification for points in the reference camera.</li><li id="a608" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph=""><code class="hi jx jy jz ka b">Tr_velo_to_cam</code> : euclidean transformation from lidar to reference camera <code class="hi jx jy jz ka b">cam0</code> .</li></ul><h1 id="ecc3" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">Projection Between Frames</h1><p id="fad3" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">Recall from linear algebra that a projection matrix, when expressed in homogenous coordinate, is simply a linear transformation that warps points through multiplication from one vector space to another vector space <strong class="hv jw">x’= Px. </strong>It can be composited to traverse across the different coordinate systems. I refer you to this <a href="https://www.youtube.com/watch?v=XkY2DOUCWMU&amp;t=" class="cm hs" rel="noopener nofollow">amazing video</a> for more explanation.</p><p id="b92a" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Transformation matrix in this context represents mainly the rigid body transformation between sensors and the perspective projection (collapsing column vector z) from 3D to 2D points. These matrices are given in the calibration files.</p><p id="10b7" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">Projection from lidar to camera 2 </strong><code class="hi jx jy jz ka b">project_velo_to_cam2</code><strong class="hv jw">: </strong>Suppose we would like to convert Velodyne points into camera coordinate, the following transformations are considered.</p><pre class="gx gy gz ha hb lh li bv"><span id="4332" class="em ir is dp ka b lj lk ll s lm" data-selectable-paragraph="">proj_mat = P_rect2cam2 @ R_ref2rect @ P_velo2cam_ref</span></pre><p id="4832" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Note that the multiplication should be performed in homogenous coordinate to simplify the calculation. To convert to pixel coordinate, simply normalise by z-coordinate.</p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="cz da ln"><div class="hh s es hi"><div class="lo hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_CVFRHvzg96GQ3DtbkpuHsA.png" width="406" height="211"></div><img alt="Image for post" class="hc hd t u v he aj c" width="406" height="211"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/812/1*CVFRHvzg96GQ3DtbkpuHsA.png" width="406" height="211" srcSet="https://miro.medium.com/max/552/1*CVFRHvzg96GQ3DtbkpuHsA.png 276w, https://miro.medium.com/max/812/1*CVFRHvzg96GQ3DtbkpuHsA.png 406w" sizes="406px"/></noscript></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 4. Transformation steps</figcaption></figure><p id="1428" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><strong class="hv jw">Projection from camera to lidar coordinate</strong>: Annotation of 3D boxes are given in camera coordinate. If we would like to convert box vertices in the camera frame to lidar, <code class="hi jx jy jz ka b">project_cam2_to_velo</code>we compute the inverse rigid transformation and transform backwards.</p><pre class="gx gy gz ha hb lh li bv"><span id="0b4b" class="em ir is dp ka b lj lk ll s lm" data-selectable-paragraph="">R_ref2rect_inv = np.linalg.inv(R_ref2rect)<em class="lp"><br></em>P_cam_ref2velo = np.linalg.inv(velo2cam_ref)</span><span id="3f7e" class="em ir is dp ka b lj lq lr ls lt lu ll s lm" data-selectable-paragraph="">proj_mat = R_ref2rect_inv @ P_cam_ref2velo</span></pre><h1 id="9800" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">Boxes In Image</h1><p id="a0d7" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">see <code class="hi jx jy jz ka b">render_image_with_boxes</code></p><p id="6253" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Boxes are commonly used to represent other agents and pedestrians. It is simpler to acquire and annotate by defining 8 vertices to fully localise the object as a box model. In my opinion, boxes might not be the best to represent pedestrians as they are not rigid.</p><p id="7e95" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">There are some other methods to represent objects which includes key points, cad model and segmentation masks that are worth considering.</p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="lb lc es ld aj"><div class="cz da lv"><div class="hh s es hi"><div class="lw hk s"><div class="we wf t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_GFnF_pAySI2vgz_XLGgGvQ.png" width="914" height="559"></div><img alt="Image for post" class="hc hd t u v he aj c" width="914" height="559"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/1828/1*GFnF_pAySI2vgz_XLGgGvQ.png" width="914" height="559" srcSet="https://miro.medium.com/max/552/1*GFnF_pAySI2vgz_XLGgGvQ.png 276w, https://miro.medium.com/max/1104/1*GFnF_pAySI2vgz_XLGgGvQ.png 552w, https://miro.medium.com/max/1280/1*GFnF_pAySI2vgz_XLGgGvQ.png 640w, https://miro.medium.com/max/1400/1*GFnF_pAySI2vgz_XLGgGvQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 5. Displaying boxes on the image plane</figcaption></figure><p id="e68c" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">From the annotation, we are given the location of the box (<strong class="hv jw">t</strong>), the yaw angle (<strong class="hv jw">R</strong>) of the box in camera coordinates (save to assume no pitch and roll) and the dimensions: height (<strong class="hv jw">h</strong>), width (<strong class="hv jw">w</strong>) and length (<strong class="hv jw">l</strong>). Note that 3D boxes of objects are annotated in camera coordinate! Given this information, we can easily transform the box model to the exact location in the camera space.</p><p id="fbf7" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Consider fig 5 above, each box instance origin is set to be at the base and centre, corresponding to the same height as the ego vehicle and ground level. To project 3D boxes to image:</p><ul class=""><li id="4079" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph="">First, we obtain the box in camera coordinate via [R|t] where <code class="hi jx jy jz ka b">R = roty</code>and <code class="hi jx jy jz ka b">t = (tx, ty, tz)</code> from the annotation in<code class="hi jx jy jz ka b">label.txt</code></li><li id="3abf" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Next, apply perspective projection to the image plane <code class="hi jx jy jz ka b">P_rect2cam2</code></li></ul><h1 id="310f" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">PointCloud in Image [3D-2D]</h1><p id="6555" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">see <code class="hi jx jy jz ka b">render_lidar_on_image</code></p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="lb lc es ld aj"><div class="cz da lx"><div class="hh s es hi"><div class="ly hk s"><div class="hc hd t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm ar wp" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_VzIm1rpoCtnyyXuR255hKQ.png" width="1242" height="375"></div><img alt="Image for post" class="we wf t u v he aj c" width="1242" height="375" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_VzIm1rpoCtnyyXuR255hKQ(1).png" srcset="https://miro.medium.com/max/276/1*VzIm1rpoCtnyyXuR255hKQ.png 276w, https://miro.medium.com/max/552/1*VzIm1rpoCtnyyXuR255hKQ.png 552w, https://miro.medium.com/max/640/1*VzIm1rpoCtnyyXuR255hKQ.png 640w, https://miro.medium.com/max/700/1*VzIm1rpoCtnyyXuR255hKQ.png 700w" sizes="700px"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/2484/1*VzIm1rpoCtnyyXuR255hKQ.png" width="1242" height="375" srcSet="https://miro.medium.com/max/552/1*VzIm1rpoCtnyyXuR255hKQ.png 276w, https://miro.medium.com/max/1104/1*VzIm1rpoCtnyyXuR255hKQ.png 552w, https://miro.medium.com/max/1280/1*VzIm1rpoCtnyyXuR255hKQ.png 640w, https://miro.medium.com/max/1400/1*VzIm1rpoCtnyyXuR255hKQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 6. Colour-coded range value of Lidar points on the image</figcaption></figure><p id="7b2a" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">If we would like to process data in 2D, more information can be gathered by projecting point cloud onto the image to construct a <strong class="hv jw">sparse depth map</strong> representation using the corresponding lidar range value (z). The sparsity depends on the number of lidar beams that map to pixels.</p><p id="14a7" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Sparse depth map are convenient and accurate range data as compared to predicting depth map from a camera. A work that used sparse depth map to enhance monocular based detection is described in <a href="https://arxiv.org/pdf/1906.06310.pdf" class="cm hs" rel="noopener nofollow">pseudo-lidar++</a>.</p><p id="bcb0" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">To map points to pixel, this is a projective transformation from lidar to image plane.</p><ul class=""><li id="541c" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph="">Compute projection matrix <code class="hi jx jy jz ka b">project_velo_to_cam2</code> .</li><li id="414d" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Project points to image plane.</li><li id="45ae" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Remove points that lie outside of image boundaries.</li></ul><h1 id="24b2" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">Boxes in PointCloud [2D-3D]</h1><p id="0b97" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">see <code class="hi jx jy jz ka b">render_lidar_with_boxes</code></p><p id="7644" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">Visualising and working in Lidar space provides the most comprehensive understanding in terms of spatial reasoning. Also, we can easily change our camera viewpoint to look at the environment from a different perspective if required.</p><figure class="gx gy gz ha hb gw cz da paragraph-image"><div class="lb lc es ld aj"><div class="cz da lz"><div class="hh s es hi"><div class="ma hk s"><div class="hc hd t u v he aj bm hf hg"><img alt="Image for post" class="t u v he aj hl hm ar wp" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_dSKfJ3S1aqY6w1ogWzQBSA.png" width="2804" height="1244"></div><img alt="Image for post" class="we wf t u v he aj c" width="2804" height="1244" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_dSKfJ3S1aqY6w1ogWzQBSA(1).png" srcset="https://miro.medium.com/max/276/1*dSKfJ3S1aqY6w1ogWzQBSA.png 276w, https://miro.medium.com/max/552/1*dSKfJ3S1aqY6w1ogWzQBSA.png 552w, https://miro.medium.com/max/640/1*dSKfJ3S1aqY6w1ogWzQBSA.png 640w, https://miro.medium.com/max/700/1*dSKfJ3S1aqY6w1ogWzQBSA.png 700w" sizes="700px"><noscript><img alt="Image for post" class="t u v he aj" src="https://miro.medium.com/max/5608/1*dSKfJ3S1aqY6w1ogWzQBSA.png" width="2804" height="1244" srcSet="https://miro.medium.com/max/552/1*dSKfJ3S1aqY6w1ogWzQBSA.png 276w, https://miro.medium.com/max/1104/1*dSKfJ3S1aqY6w1ogWzQBSA.png 552w, https://miro.medium.com/max/1280/1*dSKfJ3S1aqY6w1ogWzQBSA.png 640w, https://miro.medium.com/max/1400/1*dSKfJ3S1aqY6w1ogWzQBSA.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="ho hp db cz da hq hr cg b fe ci gh" data-selectable-paragraph="">Fig 7. 3D boxes projected onto point clouds</figcaption></figure><p id="29eb" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">In this example, instead of drawing all the scanned points from the 360 deg rotated LIDAR scanner, we shall only consider point clouds that lie within the field of view of the camera as shown in fig 4. The step taken are similar to the example on points cloud in image. Next, we will need to apply the inverse transformation to project the 3D boxes in camera coordinate to LIDAR using the projection <code class="hi jx jy jz ka b">project_cam2_to_velo</code> .</p><p id="b881" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">The steps are as follows:</p><ul class=""><li id="386a" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ks kt ku em" data-selectable-paragraph="">Compute projection matrix <code class="hi jx jy jz ka b">project_velo_to_cam2</code> .</li><li id="4e46" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Project points to image plane.</li><li id="7e2f" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Remove points that lie outside of image boundaries.</li><li id="9950" class="ht hu dp hv b hw kv hy hz ia kw ic id ie kx ig ih ii ky ik il im kz io ip iq ks kt ku em" data-selectable-paragraph="">Project 3D boxes to LIDAR coordinate</li></ul><h1 id="d592" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">To End Off</h1><p id="9df9" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">Understanding how to transform data from one sensor to another is essential to develop the performance of our algorithm. For example, suppose we are working on monocular based 3D detector, lidar points provide a sanity check on the precision of our detector when registering the 3D boxes to the lidar points.</p><p id="1b67" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">However, when it comes to sensor fusion itself, the task still remains a challenge as the multimodal sensors have several differences in the way data are stored and process as explained. This makes it difficult to align geometrically and temporally at runtime. Good calibration is essential, to begin with.</p><blockquote class="mb mc md"><p id="2421" class="ht hu lp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph=""><em class="dp">Thank you for reading this article. Hope it gave you some good insights! Follow to see more post on computer vision and machine learning. If you have any questions, feel free to leave a message, private note or any feedback:)</em></p></blockquote></div></div></section><div class="n p en me mf mg" role="separator"><span class="mh fc gf mi mj mk"></span><span class="mh fc gf mi mj mk"></span><span class="mh fc gf mi mj"></span></div><section class="dh di dj dk dl"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="gx gy gz ha hb ml"><a href="https://github.com/darylclimb/cvml_project/tree/master/projections/lidar_camera_projection" target="_blank" rel="noopener nofollow"><div class="mm n aq"><div class="mn n mo p mp mq"><h2 class="dq b mr ms bm mt fi fj mu fl fm do em">darylclimb/cvml_project</h2><div class="mv s"><h3 class="cg b lj ci bm mw fi fj mu fl fm gh">Projects and application using computer vision and machine learning - darylclimb/cvml_project</h3></div><div class="mx s"><h4 class="cg b ch ci bm mw fi fj mu fl fm gh">github.com</h4></div></div><div class="my s"><div class="mz s na nb nc my nd ne ml"></div></div></div></a></div></div></div></section><div class="n p en me mf mg" role="separator"><span class="mh fc gf mi mj mk"></span><span class="mh fc gf mi mj mk"></span><span class="mh fc gf mi mj"></span></div><section class="dh di dj dk dl"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="gx gy gz ha hb ml"><a href="https://towardsdatascience.com/depth-estimation-1-basics-and-intuition-86f2c9538cd1" target="_blank" rel="noopener"><div class="mm n aq"><div class="mn n mo p mp mq"><h2 class="dq b mr ms bm mt fi fj mu fl fm do em">Depth Estimation: Basics and Intuition</h2><div class="mv s"><h3 class="cg b lj ci bm mw fi fj mu fl fm gh">Understanding how far things are relative to a camera remains difficult but absolutely necessary for exciting…</h3></div><div class="mx s"><h4 class="cg b ch ci bm mw fi fj mu fl fm gh">towardsdatascience.com</h4></div></div><div class="my s"><div class="nf s na nb nc my nd ne ml"></div></div></div></a></div><h1 id="ef8b" class="kb is dp cg it kc kd hy ix ke kf ic jb kg kh ki jf kj kk kl jj km kn ko jn kp em" data-selectable-paragraph="">Reference</h1><p id="373f" class="ht hu dp hv b hw jp hy hz ia jq ic id ie jr ig ih ii js ik il im jt io ip iq dh em" data-selectable-paragraph="">[1] Sourabh Vora, Alex H. Lang, Bassam Helou, Oscar Beijbom. PointPainting: Sequential Fusion for 3D Object Detection, 2019</p><p id="61a3" class="ht hu dp hv b hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq dh em" data-selectable-paragraph="">[2] A. Geiger, F. Moosmann, O. Car, and B. Schuster, “A toolbox for automatic calibration of range and camera sensors using a single shot,” in ICRA, 2012</p></div></div></section></div></article><div class="we dg nh ng aj wj nl no" data-test-id="post-sidebar"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="np n mo"><div class="wq"><div><div class="nq nr s"><a href="https://medium.com/swlh?source=post_sidebar--------------------------post_sidebar-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><h2 class="cg it lj ci do em dh">The Startup</h2></a><div class="ns nt s"><h4 class="cg b fe ci bm nu fi fj nv fl fm gh">Medium's largest active publication, followed by +716K people. Follow to join our community.</h4></div><div class="gf" aria-hidden="false"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg"><div class="n ew">Follow</div></button></span></div></div><div class="oc od oe n"><div class="n o"><div class="s es of og oh oi oj"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_sidebar-----911c78167a94---------------------clap_sidebar-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><div class="ba ok ol om on oo op oq r or os"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s ot ou ov ow ox oy oz"><div class="pa"><h4 class="cg b fe ci gh"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp">336 </button></h4></div></div></div></div><div class="od s"><button class="on ol ba"><div class="pd n o ew"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg><div class="s es pe pf pg ph pi pj pk pl"></div></div></button></div><div class="gt"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_sidebar-----911c78167a94---------------------bookmark_sidebar-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div><div class="we wq ng nh ni fa nj nk nl nm"></div><div><div class="pm gw n mo p"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="n pn"></div><div class="n o pn"></div><div class="po s"><ul class="ba bb"><li class="gf bs gu pp"><a href="https://medium.com/swlh/tagged/machine-learning" class="cg b ch pq gh pr ps gg s li">Machine Learning</a></li><li class="gf bs gu pp"><a href="https://medium.com/swlh/tagged/python" class="cg b ch pq gh pr ps gg s li">Python</a></li><li class="gf bs gu pp"><a href="https://medium.com/swlh/tagged/computer-vision" class="cg b ch pq gh pr ps gg s li">Computer Vision</a></li><li class="gf bs gu pp"><a href="https://medium.com/swlh/tagged/autonomous-vehicles" class="cg b ch pq gh pr ps gg s li">Autonomous Vehicles</a></li><li class="gf bs gu pp"><a href="https://medium.com/swlh/tagged/robotics" class="cg b ch pq gh pr ps gg s li">Robotics</a></li></ul></div><div class="po n eo z"><div class="n ew"><div class="pt s"><span class="s pu pv pw e d"><div class="n o"><div class="s es of og oh oi oj"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_actions_footer-----911c78167a94---------------------clap_footer-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><div class="ba ok ol om on oo op oq r or os"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s ot ou ov ow ox oy oz"><div class="es px pa"><h4 class="cg b fe ci em"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp">336<span class="s h g f py pz">&nbsp;claps</span></button><span class="s h g f py pz"></span></h4></div></div></div></span><span class="s h g f py pz"><div class="n bw"><div class="s es of og"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Fswlh%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_actions_footer-----911c78167a94---------------------clap_footer-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><div class="ba ok ol om on oo op oq r or os"><svg width="33" height="33" viewBox="0 0 33 33" aria-label="clap"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></a></span></div><div class="s ot ou ov ow qa qb qc qd qe qf"><div class="es px pa"><h4 class="cg b fe ci em"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp">336<span class="s h g f py pz">&nbsp;claps</span></button><span class="s h g f py pz"></span></h4></div></div></div></span></div><div class="s qg qh qi qj qk"></div><button class="on ol ba"><div class="pd n o ew"><span class="ql s h g f py pz"><svg width="33" height="33" viewBox="0 0 33 33" fill="none" class="r" aria-label="responses"><path clip-rule="evenodd" d="M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z"></path></svg></span><span class="qm s pu pv pw e d"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></span><div class="s es qn pf qo ph qp pj qq qr qs qt"></div></div></button></div><div class="n o"><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on twitter"><svg width="29" height="29" class="gt"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on linkedin"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="gt"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="gq s aq"><button class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" aria-label="Share on facebook"><svg width="29" height="29" class="gt"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="qu s aq"><div class="gt"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F911c78167a94&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fswlh%2Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94&amp;source=post_actions_footer--------------------------bookmark_footer-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div><div><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="qv qw qx po s qy z"><div class="s g"><div class="qz ra s es"><span class="s rb am rc"><div class="s t rd re"><a rel="noopener" href="https://medium.com/@daryl.tanyj?source=follow_footer--------------------------follow_footer-----------"><div class="es rf bz"><div class="ev n ew o p t ex ey ez fa fb dg"><svg width="91" height="91" viewBox="0 0 91 91"><path fill-rule="evenodd" clip-rule="evenodd" d="M45.5 1.4c-17.14 0-32 9.95-39.25 24.5L5 25.28C12.47 10.28 27.8 0 45.5 0S78.53 10.29 86 25.28l-1.25.62C77.5 11.35 62.65 1.4 45.5 1.4zM6.25 65.1c7.25 14.55 22.1 24.5 39.25 24.5 17.14 0 32-9.95 39.25-24.5l1.25.62C78.53 80.72 63.2 91 45.5 91S12.47 80.71 5 65.72l1.25-.62z"></path></svg></div><img alt="Daryl Tan" class="s fc bz rf" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/2_HNVsBoEb2aYvPS_Mitihog(1).png" width="80" height="80"></div></a></div><span class="s"><div class="rg s rh"><p class="cg b ch ri rj gh ck">Written by</p></div><div class="rg rk n rh"><div class="aj n o eo"><h2 class="cg it rl ms do em"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener" href="https://medium.com/@daryl.tanyj?source=follow_footer--------------------------follow_footer-----------">Daryl Tan</a></h2><div class="s g"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg">Follow</button></span></div></div></div></span></span><div class="rg rm s rh bk"><div class="rn s"><h4 class="cg b lj ro gh">AV Machine Learning Engineer</h4></div><div class="rp rq bk"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg">Follow</button></span></div></div></div><div class="qv s"></div><div class="qz ra s es"><span class="s rb am rc"><div class="s t rd re"><a href="https://medium.com/swlh?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><img alt="The Startup" class="gc rf bz" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_Xd2uZaVHfrGOP14W_3UQRg.jpeg" width="80" height="80"></a></div><span class="s"><div class="rg rk n rh"><div class="aj n o eo"><h2 class="cg it rl ms do em"><a href="https://medium.com/swlh?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener">The Startup</a></h2><div class="s g"><div class="gf" aria-hidden="false"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg"><div class="n ew">Follow</div></button></span></div></div></div></div></span></span><div class="rg rr s rh bk"><div class="rn s"><h4 class="cg b lj ro gh">Medium's largest active publication, followed by +716K people. Follow to join our community.</h4></div><div class="rp rq bk"><div class="gf" aria-hidden="false"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg"><div class="n ew">Follow</div></button></span></div></div></div></div></div><div class="rp bk"><div class="mf s"><div class="n ew"><div class="rs s"><a rel="noopener" href="https://medium.com/@daryl.tanyj?source=follow_footer--------------------------follow_footer-----------"><div class="es rt ru"><div class="ev n ew o p t ex ey ez fa fb dg"><svg width="49" height="49" viewBox="0 0 49 49"><path fill-rule="evenodd" clip-rule="evenodd" d="M24.5 1.1c-9.39 0-17.53 5.55-21.51 13.66L2 14.28C6.15 5.82 14.66 0 24.5 0S42.85 5.82 47 14.28l-.99.48C42.03 6.65 33.9 1.1 24.5 1.1zM2.99 34.24C6.97 42.35 15.1 47.9 24.5 47.9c9.39 0 17.53-5.55 21.51-13.66l.99.48C42.85 43.18 34.34 49 24.5 49S6.15 43.18 2 34.72l.99-.48z"></path></svg></div><img alt="Daryl Tan" class="s fc ru rt" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/2_HNVsBoEb2aYvPS_Mitihog(2).png" width="40" height="40"></div></a></div><div class="fd s"><p class="cg b rv rw rx gh ck">Written by</p><div class="n ew"><h2 class="cg it lj ci do em"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener" href="https://medium.com/@daryl.tanyj?source=follow_footer--------------------------follow_footer-----------">Daryl Tan</a></h2><div class="fd s"><span><button class="cg b ch ci at fr fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg">Follow</button></span></div></div><div class="ry s"><h4 class="cg b fe ci gh">AV Machine Learning Engineer</h4></div></div></div><div class="mf s"><div class="n ew"><a href="https://medium.com/swlh?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><img alt="The Startup" class="gc rt ru" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_Xd2uZaVHfrGOP14W_3UQRg(1).jpeg" width="40" height="40"></a><div class="fd s"><div class="n ew"><h2 class="cg it lj ci do em"><a href="https://medium.com/swlh?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp" rel="noopener">The Startup</a></h2><div class="fd s"><div class="gf" aria-hidden="false"><span><button class="cg b fe ci at nw fs au nx bd be ny bc fx fy nz oa ob gc gd ge dc gf gg"><div class="n ew">Follow</div></button></span></div></div></div><div class="ry s"><h4 class="cg b fe ci gh">Medium's largest active publication, followed by +716K people. Follow to join our community.</h4></div></div></div></div></div></div></div><div class="rz qw s qy sa z"></div></div></div><div class="s sb z"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="sc sd s"><div class="se nr sf sd s sg sh"><h2 class="cg it iu iw ix iy ja jb jc je jf jg ji jj jk jm jn em">More From Medium</h2></div><div class="bw n ew pn si sj sk sl sm sn so sp sq sr ss st su sv sw"><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/swlh/a-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6?source=post_internal_links---------0----------------------------">A 3 step guide to assess any business use-case of AI</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@uday.marepalli?source=post_internal_links---------0----------------------------">Uday Marepalli</a><span> <!-- -->in<!-- --> <a href="https://medium.com/swlh?source=post_internal_links---------0----------------------------" class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener">The Startup</a></span></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/swlh/a-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6?source=post_internal_links---------0----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_J9SQ1JdVMe1pSB-jePs1zg.jpeg" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*J9SQ1JdVMe1pSB-jePs1zg.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*J9SQ1JdVMe1pSB-jePs1zg.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*J9SQ1JdVMe1pSB-jePs1zg.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d?source=post_internal_links---------1----------------------------">Using Machine Learning to Predict Value of Homes On Airbnb</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@rchang?source=post_internal_links---------1----------------------------">Robert Chang</a><span> <!-- -->in<!-- --> <a href="https://medium.com/airbnb-engineering?source=post_internal_links---------1----------------------------" class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener">Airbnb Engineering &amp; Data Science</a></span></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d?source=post_internal_links---------1----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_jdUbWGwyIyJJ4wlr1FaSqA.png" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*jdUbWGwyIyJJ4wlr1FaSqA.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*jdUbWGwyIyJJ4wlr1FaSqA.png 48w, https://miro.medium.com/fit/c/140/140/1*jdUbWGwyIyJJ4wlr1FaSqA.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/@673/machine-learning-from-human-imagination-to-real-life-93238633447e?source=post_internal_links---------2----------------------------">Machine Learning: from human imagination to real life</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@673?source=post_internal_links---------2----------------------------">Van Phan</a></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/@673/machine-learning-from-human-imagination-to-real-life-93238633447e?source=post_internal_links---------2----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_6gGuWfqcyBFT2_h-vIaXpA.jpeg" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*6gGuWfqcyBFT2_h-vIaXpA.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*6gGuWfqcyBFT2_h-vIaXpA.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*6gGuWfqcyBFT2_h-vIaXpA.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/capital-one-tech/system-language-agnostic-hyperparameter-optimization-at-scale-and-its-importance-for-automl-92d9f9add416?source=post_internal_links---------3----------------------------">System &amp; Language Agnostic Hyperparameter Optimization at Scale</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@jeremygoodsitt?source=post_internal_links---------3----------------------------">Jeremy Goodsitt</a><span> <!-- -->in<!-- --> <a href="https://medium.com/capital-one-tech?source=post_internal_links---------3----------------------------" class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener">Capital One Tech</a></span></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/capital-one-tech/system-language-agnostic-hyperparameter-optimization-at-scale-and-its-importance-for-automl-92d9f9add416?source=post_internal_links---------3----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_JgRLAbBUxzaigOAkkdkLYQ.png" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*JgRLAbBUxzaigOAkkdkLYQ.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*JgRLAbBUxzaigOAkkdkLYQ.png 48w, https://miro.medium.com/fit/c/140/140/1*JgRLAbBUxzaigOAkkdkLYQ.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/@severinperez/exploring-literature-with-the-stanza-nlp-package-927d5b6556bf?source=post_internal_links---------4----------------------------">Exploring Literature with the Stanza NLP Package</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@severinperez?source=post_internal_links---------4----------------------------">Severin Perez</a></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/@severinperez/exploring-literature-with-the-stanza-nlp-package-927d5b6556bf?source=post_internal_links---------4----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/0_A0qSZq1aE8w42YZg" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/0*A0qSZq1aE8w42YZg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*A0qSZq1aE8w42YZg 48w, https://miro.medium.com/fit/c/140/140/0*A0qSZq1aE8w42YZg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/analytics-vidhya/embedding-sentiment-analysis-model-into-a-web-application-93b76ab6348c?source=post_internal_links---------5----------------------------">Embedding Sentiment Analysis Model into a Web Application</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@soumyansh?source=post_internal_links---------5----------------------------">Soumya Gupta</a><span> <!-- -->in<!-- --> <a href="https://medium.com/analytics-vidhya?source=post_internal_links---------5----------------------------" class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener">Analytics Vidhya</a></span></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/analytics-vidhya/embedding-sentiment-analysis-model-into-a-web-application-93b76ab6348c?source=post_internal_links---------5----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_f0cx1ECtYBHpP5FSQGPHXA.jpeg" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*f0cx1ECtYBHpP5FSQGPHXA.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*f0cx1ECtYBHpP5FSQGPHXA.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*f0cx1ECtYBHpP5FSQGPHXA.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/@yingbiao/ner-with-bert-in-action-936ff275bc73?source=post_internal_links---------6----------------------------">NER with BERT in Action</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@yingbiao?source=post_internal_links---------6----------------------------">Bill Huang</a></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/@yingbiao/ner-with-bert-in-action-936ff275bc73?source=post_internal_links---------6----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_BqOmPcklT4b32YcKEmz3pg.png" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*BqOmPcklT4b32YcKEmz3pg.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*BqOmPcklT4b32YcKEmz3pg.png 48w, https://miro.medium.com/fit/c/140/140/1*BqOmPcklT4b32YcKEmz3pg.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr"><div class="ts tt s"><div class="aj he"><div class="n eo"><div class="s br tu tv tw"><div class="tx s"><h2 class="cg it ty tz ix ua ub jb uc ud jf ue uf jj ug uh jn em"><a rel="noopener" href="https://medium.com/@DaniG2k/inside-the-neural-network-a-brief-introduction-9344085f0386?source=post_internal_links---------7----------------------------">Inside the Neural Network — a brief introduction</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fe ci em"><div class="cs n o fg"><span class="cg b ch ci em"><a class="cm cn av aw ax ay az ba bb bc fn bf fo fp" rel="noopener" href="https://medium.com/@DaniG2k?source=post_internal_links---------7----------------------------">Daniele Pestilli</a></span></div></span></div></div></div></div></div><div class="fd gu s ui uj"><a class="cm cn av aw ax ay az ba bb bc gr gs bf fo fp s" rel="noopener" href="https://medium.com/@DaniG2k/inside-the-neural-network-a-brief-introduction-9344085f0386?source=post_internal_links---------7----------------------------"><div class="hh s es hi"><div class="uk hk s"><div class="we wf t u v he aj bm hf hg"><img class="t u v he aj hl hm hn" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_wQKLVH7-p7ZTylHXfp-gIw.png" width="70" height="70" role="presentation"></div><img class="hc hd ul um un uo up uq ur us ut uu c" width="70" height="70" role="presentation"><noscript><img class="ul um un uo up uq ur us ut uu" src="https://miro.medium.com/fit/c/140/140/1*wQKLVH7-p7ZTylHXfp-gIw.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*wQKLVH7-p7ZTylHXfp-gIw.png 48w, https://miro.medium.com/fit/c/140/140/1*wQKLVH7-p7ZTylHXfp-gIw.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="uv s uw ux"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="uy uz qz n eo g"><div class="va n eo"><div class="vb s vc"><div class="tx s"><a class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----911c78167a94--------------------------------"><h2 class="cg it mr ro do vh">Learn more.</h2></a></div><h4 class="cg b fe ci vi">Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.
                        Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. <a class="cm cn av aw ax ay az ba bb bc bf vf vg hs" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----911c78167a94--------------------------------">Learn more</a></h4></div><div class="vb s vc"><div class="tx s"><a href="https://medium.com/topics?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener"><h2 class="cg it mr ro do vh">Make <!-- -->Medium<!-- --> yours<!-- -->.</h2></a></div><h4 class="cg b fe ci vi">Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. <a href="https://medium.com/topics?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc bf vf vg hs" rel="noopener">Explore</a></h4></div><div class="vb s vc"><div class="tx s"><a href="https://about.medium.com/creators/?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener"><h2 class="cg it mr ro do vh">Share your thinking.</h2></a></div><h4 class="cg b fe ci vi">If you have a story to tell, knowledge to share, or a perspective to offer — welcome home.
        It’s easy and free to post your thinking on any topic. <a href="https://about.medium.com/creators/?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc bf vf vg hs" rel="noopener">Write on Medium</a></h4></div></div></div><div class="n mo"><div class="n o eo"><a aria-label="Go to homepage" class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener" href="https://medium.com/?source=post_page-----911c78167a94--------------------------------"><svg viewBox="0 0 3940 610" class="vj vk"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><h4 class="cg b fe ci vi"><div class="ry vl n eo vm am"><h4 class="cg b lj ro vh"><a class="cm cn av aw ax ay az ba bb bc fn bf vf vg" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----911c78167a94--------------------------------">About</a></h4><h4 class="cg b lj ro vh"><a href="https://help.medium.com/hc/en-us?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc fn bf vf vg" rel="noopener">Help</a></h4><h4 class="cg b lj ro vh"><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc fn bf vf vg" rel="noopener">Legal</a></h4></div></h4></div><div class="rp vn vo am"><h4 class="cg b lj ro vi">Get the Medium app</h4></div><div class="rp vn vp am vq"><div class="vr s"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener nofollow"><img alt="A button that says &#39;Download on the App Store&#39;, and if clicked it will lead you to the iOS App store" class="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"></a></div><div class="s"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----911c78167a94--------------------------------" class="cm cn av aw ax ay az ba bb bc vd ve bf vf vg" rel="noopener nofollow"><img alt="A button that says &#39;Get it on, Google Play&#39;, and if clicked it will lead you to the Google Play store" class="" src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/1_W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"></a></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = "main-20201016-200229-6444e2d97a"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"auroraPage":{"isAuroraPageEnabled":false},"config":{"nodeEnv":"production","version":"main-20201016-200229-6444e2d97a","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20201016-200229-6444e2d97a"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"main-20201016-200229-6444e2d97a","commit":"6444e2d97a765554b77c08bd6f4823d2bc2eaf03"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e","9dc80918cc93","8a9336e5bb4","cef6983b292","54c98c43354d","193b68bd4fba","b7e45b22fec3"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":["pandemic","epidemic","coronavirus","covid19","co-vid-19","containment","self-care","flatten-the-curve","public-health","virus","public-health-crisis","quarantine","self-quarantine","zika","corona","disease-prevention","wuhan","chinavirus","outbreak","influenza","socialdistancing","social-distance","flu","vaccines","healthcare","medicine","conspiracy-theories","conspiracy","virality","epidemia","pandemia","salud","corona-e-virus","coronavirus-covid19","covid-19","covid-19-symptoms","covid-19-crisis","covid-19-testing","covid-19-treatment","coronavirus-update","coronavirus-diaries"],"COVID_APPLICABLE_TOPIC_NAMES":["coronavirus"],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":["coronavirus","health"],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Check your U.S. voter registration status or register to vote here.","markups":[{"start":62,"end":66,"href":"https:\u002F\u002Fwww.vote.org\u002F"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v"},"debug":{"requestId":"ddeeb96d-7e46-4b71-b282-9b44425fa8b0","originalSpanCarrier":{"ot-tracer-spanid":"1c18e6330f6875a9","ot-tracer-traceid":"7a5da2f701d88f4c","ot-tracer-sampled":"true"}},"session":{"user":{"id":"lo_4561028927ed"},"xsrf":"","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94","host":"medium.com","hostname":"medium.com","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isEu":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":true,"inAppBrowserName":"","routingEntity":{"type":"DEFAULT","explicit":false},"supportsWebp":true},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"assign_default_topic_to_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"bane_add_user","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bane_verify_domain","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"branch_seo_metadata","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"default_seo_post_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_android_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_resume_reading_toast","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_post_recommended_from_friends_provider","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_about_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_add_membership_lock","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_admin_mark_as_paid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_local_currency","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_crossgrading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_failure","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_status","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_general_admission","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_about_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profiles_for_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_forfeit_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automated_mission_control_triggers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_avatar_component_in_newsletterv3_settings_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding_fonts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cleansweep_double_writes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_confirm_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creators_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cta_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_curation_priority_queue_experiment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dedicated_series_tab_api_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_detailed_billing_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_different_grid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_feature_logging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_disregard_trunc_state_for_footer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_earn_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_edit_alt_text","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_address_sharing_setting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_embedding_based_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_end_of_post_cleanup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_expire_processor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_first_name_on_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_free_corona_topic","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_global_susi_modal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import_export_newsletter_audience","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_post_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_janky_spam_rules","valueType":{"__typename":"VariantFlagString","value":"users,posts"}},{"__typename":"VariantFlag","name":"enable_json_logs_trained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_app_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_daily_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_about_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_lo_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notifications","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pay_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_cd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights_view_only","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_header_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_unread_notification_count_mutation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lo_open_in_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_media_resource_try_catch","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_remove_section_a","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_meta_header_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_miro_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_more_on_coronavirus","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_checkout_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_collaborative_filtering_data","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_suspended_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_open_in_app_regwall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_optimizely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_parsely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_patronus_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_popularity_feature","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_page_nav_stickiness_removal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_seo_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_table_of_contents","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_primary_topic_for_mobile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_page_seo_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_subdomains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_edit_and_delete","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_moderation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rtr_channel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_save_to_medium","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sohne","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace_ranker_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_topic_lifecycle_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trending_posts_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_unbound","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"filter_stripe_invoice_line_items","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_embed_commands","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"google_sign_in_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_generic_home_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_iceland_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_pub_follow_email_opt_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"is_not_medium_subscriber","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_fastrak","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_stripe_express","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"make_nav_sticky","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"new_transition_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_post_post_similarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"retrained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sign_up_with_email_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"use_new_admin_topic_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"vote_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"xgboost_auto_suspend","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"meterPost({\"postId\":\"911c78167a94\",\"postMeteringOptions\":{}})":{"__ref":"MeteringInfo:{}"},"postResult({\"id\":\"911c78167a94\"})":{"__ref":"Post:911c78167a94"}},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":["885223e5e9b7","911c78167a94"],"maxUnlockCount":3,"unlocksRemaining":1},"ImageMetadata:":{"id":"","__typename":"ImageMetadata"},"ImageMetadata:1*IOJrKVmLnRcFz3E_KrrN_Q.png":{"id":"1*IOJrKVmLnRcFz3E_KrrN_Q.png","__typename":"ImageMetadata","originalWidth":607,"originalHeight":104},"User:d43c46db5b92":{"id":"d43c46db5b92","__typename":"User"},"ImageMetadata:1*Xd2uZaVHfrGOP14W_3UQRg.jpeg":{"id":"1*Xd2uZaVHfrGOP14W_3UQRg.jpeg","__typename":"ImageMetadata"},"NewsletterV3:13df37cfc4c2":{"id":"13df37cfc4c2","__typename":"NewsletterV3","slug":"editors-note","isSubscribed":false,"showPromo":false,"name":"Editor's Note","description":"----------","collection":{"__ref":"Collection:f5af2b715248"}},"Collection:f5af2b715248":{"id":"f5af2b715248","__typename":"Collection","domain":null,"googleAnalyticsId":null,"slug":"swlh","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraVisible":false,"favicon":{"__ref":"ImageMetadata:"},"name":"The Startup","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFF4F2F2","point":0},{"__typename":"ColorPoint","color":"#FFF2F0F0","point":0.1},{"__typename":"ColorPoint","color":"#FFF0EEEE","point":0.2},{"__typename":"ColorPoint","color":"#FFEEECEC","point":0.3},{"__typename":"ColorPoint","color":"#FFECEBEA","point":0.4},{"__typename":"ColorPoint","color":"#FFEAE9E8","point":0.5},{"__typename":"ColorPoint","color":"#FFE8E7E7","point":0.6},{"__typename":"ColorPoint","color":"#FFE6E5E5","point":0.7},{"__typename":"ColorPoint","color":"#FFE4E3E3","point":0.8},{"__typename":"ColorPoint","color":"#FFE2E1E1","point":0.9},{"__typename":"ColorPoint","color":"#FFE0DFDF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF848585","point":0},{"__typename":"ColorPoint","color":"#FF7B7B7B","point":0.1},{"__typename":"ColorPoint","color":"#FF717272","point":0.2},{"__typename":"ColorPoint","color":"#FF686868","point":0.3},{"__typename":"ColorPoint","color":"#FF5E5E5E","point":0.4},{"__typename":"ColorPoint","color":"#FF545454","point":0.5},{"__typename":"ColorPoint","color":"#FF494A4A","point":0.6},{"__typename":"ColorPoint","color":"#FF3F3F3F","point":0.7},{"__typename":"ColorPoint","color":"#FF333333","point":0.8},{"__typename":"ColorPoint","color":"#FF272727","point":0.9},{"__typename":"ColorPoint","color":"#FF1A1A1A","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFF9F9F9","colorPoints":[{"__typename":"ColorPoint","color":"#FFF9F9F9","point":0},{"__typename":"ColorPoint","color":"#FFE7E7E7","point":0.1},{"__typename":"ColorPoint","color":"#FFD4D4D4","point":0.2},{"__typename":"ColorPoint","color":"#FFC1C1C1","point":0.3},{"__typename":"ColorPoint","color":"#FFADADAE","point":0.4},{"__typename":"ColorPoint","color":"#FF989999","point":0.5},{"__typename":"ColorPoint","color":"#FF838484","point":0.6},{"__typename":"ColorPoint","color":"#FF6D6E6E","point":0.7},{"__typename":"ColorPoint","color":"#FF565757","point":0.8},{"__typename":"ColorPoint","color":"#FF3C3E3E","point":0.9},{"__typename":"ColorPoint","color":"#FF202122","point":1}]}},"customStyleSheet":null,"description":"Medium's largest active publication, followed by +716K people. Follow to join our community.","shortDescription":"Medium's largest active publication, followed by +716K…","tagline":"Medium's largest active publication, followed by +716K people. Follow to join our community.","isAuroraEligible":false,"viewerIsEditor":false,"logo":{"__ref":"ImageMetadata:1*IOJrKVmLnRcFz3E_KrrN_Q.png"},"navItems":[{"__typename":"NavItem","title":"We’re Reimagining The Startup","url":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fa-call-for-great-stories-were-reimagining-the-startup-medium-s-largest-publication-with-680k-b06013ae1017","type":"POST_NAV_ITEM"},{"__typename":"NavItem","title":"Are you curious?","url":"https:\u002F\u002Fmedium.com\u002Fcurious","type":"EXTERNAL_LINK_NAV_ITEM"}],"creator":{"__ref":"User:d43c46db5b92"},"subscriberCount":716103,"avatar":{"__ref":"ImageMetadata:1*Xd2uZaVHfrGOP14W_3UQRg.jpeg"},"isEnrolledInHightower":false,"newsletterV3":{"__ref":"NewsletterV3:13df37cfc4c2"},"viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"viewerIsMuting":false,"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"ampEnabled":false,"twitterUsername":"thestartup_","facebookPageId":null},"User:d5d47d10c0e9":{"id":"d5d47d10c0e9","__typename":"User","isSuspended":false,"name":"Daryl Tan","username":"daryl.tanyj","bio":"AV Machine Learning Engineer","hasDomain":false,"customStyleSheet":null,"isAuroraVisible":true,"socialStats":{"__typename":"SocialStats","followerCount":154},"isBlocking":null,"imageId":"2*HNVsBoEb2aYvPS_Mitihog.png","mediumMemberAt":1574603122000,"isMuting":null,"isFollowing":null,"allowNotes":true,"twitterScreenName":"","isPartnerProgramEnrolled":false},"Paragraph:edc4671f53e1_0":{"id":"edc4671f53e1_0","__typename":"Paragraph","name":"b14b","text":"Camera-Lidar Projection: Navigating between 2D and 3D","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_1":{"id":"edc4671f53e1_1","__typename":"Paragraph","name":"c16d","text":"Figure 1. Lidar points on image (source)","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*-WFfHL24zz_mOZM7_blSOQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":33,"end":39,"type":"A","href":"https:\u002F\u002Frobotcar-dataset.robots.ox.ac.uk\u002Fimages\u002FProjectLaserIntoCamera.png","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_2":{"id":"edc4671f53e1_2","__typename":"Paragraph","name":"2782","text":"Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a means for detection and localisation of other objects, giving robots rich semantic information required for safe navigation. Many researchers have started exploring multi-modal approaches for precise 3D object detection. An interesting example would be an algorithm developed by Aptiv, PointPainting[1]","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_3":{"id":"edc4671f53e1_3","__typename":"Paragraph","name":"42f6","text":"So why is this 2 sensor complimentary?","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":38,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_4":{"id":"edc4671f53e1_4","__typename":"Paragraph","name":"2ee2","text":"Camera outperforms LIDAR when it comes to capturing denser and richer representation. From fig 2, looking at the sparse point cloud alone, it is relatively difficult to correctly identify the black box as a pedestrian. However, paying attention to the RGB image, even with the person back facing, we could easily tell the object looks like a pedestrian. Besides that, other useful visual features that could be extracted include traffic light and road sign which LIDAR struggles.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_5":{"id":"edc4671f53e1_5","__typename":"Paragraph","name":"94d0","text":"Fig 2. RGB & Point cloud representation with pedestrian detection","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*BrOLss3ODN_JGUG5rI-WBw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_6":{"id":"edc4671f53e1_6","__typename":"Paragraph","name":"55d7","text":"In contrast, lidar excels when it comes to extracting distance information. It is extremely difficult to measure distance using the camera in standard perspective view which I explained in my previous post.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":192,"end":205,"type":"A","href":"https:\u002F\u002Ftowardsdatascience.com\u002Finverse-projection-transformation-c866ccedef1c","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_7":{"id":"edc4671f53e1_7","__typename":"Paragraph","name":"0b48","text":"By fusing information from both sensors, the idea is we could leverage the advantages of both sensors, overcoming individual limitations. Having multiple sensors on-board also allows for redundancy, which is a crucial element in safe autonomous driving in the event of sensor failure.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":187,"end":197,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_8":{"id":"edc4671f53e1_8","__typename":"Paragraph","name":"447a","text":"Objective","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":9,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_9":{"id":"edc4671f53e1_9","__typename":"Paragraph","name":"ac83","text":"In this post, I would like to take a step further into how LIDAR and camera data can be simultaneously leveraged and fused to create a more enriching and accurate 3D scene of the environment. But if you need a quick guide on the two sensors, I would recommend this post ;) What you need to understand is LIDAR process data as 3D point clouds and camera as pixels points in 3D or pixels on a 2D plane.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":265,"end":269,"type":"A","href":"https:\u002F\u002Fblogs.nvidia.com\u002Fblog\u002F2019\u002F04\u002F15\u002Fhow-does-a-self-driving-car-see\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_10":{"id":"edc4671f53e1_10","__typename":"Paragraph","name":"1edf","text":"We will use Kitti 3D object detection dataset as a reference. Refer to the Kitti Dataset website or to the code on Github under the folder data to understand the data format.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":139,"end":143,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":12,"end":46,"type":"A","href":"http:\u002F\u002Fwww.cvlibs.net\u002Fdatasets\u002Fkitti\u002Feval_object.php?obj_benchmark=3d","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":107,"end":121,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fdarylclimb\u002Fcvml_project\u002Ftree\u002Fmaster\u002Fprojections\u002Flidar_camera_projection","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_11":{"id":"edc4671f53e1_11","__typename":"Paragraph","name":"63c6","text":"For the rest of this article, we will first need to discuss the problem set up with regards to sensor placement and go through the Kitti object detection dataset to understand the data structure. How the calibration is done to understand the calibration matrices. Next, go in detail on 3D-2D and 2D-3D projection mapping, and finally, show the different types of lidar-camera data representation visually. All inline text format are either functions, variables or files in the code.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":410,"end":416,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":464,"end":481,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fdarylclimb\u002Fcvml_project\u002Ftree\u002Fmaster\u002Fprojections\u002Flidar_camera_projection","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_12":{"id":"edc4671f53e1_12","__typename":"Paragraph","name":"f07f","text":"Sensor Setup, Calibration and Coordinate System (KITTI)","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_13":{"id":"edc4671f53e1_13","__typename":"Paragraph","name":"1d6a","text":"Fig 3. Kitti ego vehicle sensor placement (facing left)","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*wMibQFL4SsSKDUkoLgi-OQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_14":{"id":"edc4671f53e1_14","__typename":"Paragraph","name":"9343","text":"Before we begin with our analysis, there is a need to know the relative position of the sensors during the data acquisition process. This is necessary information to perform any transformation between one coordinate frame to another. Note that each sensor has its own coordinate frame as shown in fig 3.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_15":{"id":"edc4671f53e1_15","__typename":"Paragraph","name":"21f3","text":"Hardware specification","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":22,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_16":{"id":"edc4671f53e1_16","__typename":"Paragraph","name":"aa34","text":"Kitti several sensors including LIDAR, grayscale camera, colour cameras and IMU onboard the vehicle. However, we will only focus on:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_17":{"id":"edc4671f53e1_17","__typename":"Paragraph","name":"f108","text":"Cam 0: Grayscale camera, left camera of a stereo rig. This is the reference camera","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":5,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_18":{"id":"edc4671f53e1_18","__typename":"Paragraph","name":"471c","text":"Cam 2: RGB colour camera, left camera of a stereo rig","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":5,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_19":{"id":"edc4671f53e1_19","__typename":"Paragraph","name":"9b55","text":"Velo: 64 beams Velodyne laser scanner","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":4,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_20":{"id":"edc4671f53e1_20","__typename":"Paragraph","name":"4f8a","text":"Coordinate System: Vehicle facing left, left-hand coordinate system (fig 3)","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":17,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_21":{"id":"edc4671f53e1_21","__typename":"Paragraph","name":"2e32","text":"What data do we have?","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":21,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_22":{"id":"edc4671f53e1_22","__typename":"Paragraph","name":"d39d","text":"Refer to data\u002Freadme.txt for more details.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":9,"end":24,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_23":{"id":"edc4671f53e1_23","__typename":"Paragraph","name":"37e5","text":"Lidar point cloud fileid.bin : 2D array with shape [num_points, 4] Each point encodes XYZ + reflectance.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":18,"end":28,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":51,"end":66,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":31,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_24":{"id":"edc4671f53e1_24","__typename":"Paragraph","name":"da9e","text":"Object instance fileid_label.txt : For each row, the annotation of each object is provided with 15 columns representing certain metadata and 3D box properties in camera coordinates:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":16,"end":32,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":35,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":162,"end":180,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_25":{"id":"edc4671f53e1_25","__typename":"Paragraph","name":"61ee","text":"type | truncation | visibility | observation angle | xmin | ymin |xmax | ymax | height | width | length | tx | ty | tz | roty","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":125,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_26":{"id":"edc4671f53e1_26","__typename":"Paragraph","name":"231d","text":"Some instances typeare marked as ‘DontCare’, indicating they are not labelled.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":15,"end":19,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_27":{"id":"edc4671f53e1_27","__typename":"Paragraph","name":"be62","text":"RGB image fileid_image.png : Image from camera 2","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":10,"end":26,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":29,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_28":{"id":"edc4671f53e1_28","__typename":"Paragraph","name":"bfc6","text":"Calibration Parameters","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":22,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_29":{"id":"edc4671f53e1_29","__typename":"Paragraph","name":"734f","text":"fileid_calib.txt","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":16,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":16,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_30":{"id":"edc4671f53e1_30","__typename":"Paragraph","name":"9a77","text":"The calibration parameters are stored in row-major order. It contains the 3x4 projection matrix parameters which describe the mapping of 3D points in the world to 2D points in an image.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_31":{"id":"edc4671f53e1_31","__typename":"Paragraph","name":"c5e4","text":"The calibration process is explained in [2]. Important things to take note is calibration is done with cam0 as the reference sensor. The laser scanner is registered with respect to the reference camera coordinate system.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":103,"end":107,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_32":{"id":"edc4671f53e1_32","__typename":"Paragraph","name":"2e0f","text":"Rectification R_ref2recthas also been considered during calibration to correct for planar alignment between cameras.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":14,"end":24,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_33":{"id":"edc4671f53e1_33","__typename":"Paragraph","name":"3e87","text":"Rectification","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*rRWRXHIHP2YvrUYU.jpg"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":13,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FImage_rectification","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_34":{"id":"edc4671f53e1_34","__typename":"Paragraph","name":"2036","text":"It contains the following information:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_35":{"id":"edc4671f53e1_35","__typename":"Paragraph","name":"1667","text":"P_rect[i]: projective transformation from rectified reference camera frame to cam[i] . Note that bx[i] denotes the baseline with respect to the reference camera 0.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":9,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":78,"end":84,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_36":{"id":"edc4671f53e1_36","__typename":"Paragraph","name":"83ac","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xhwMXO8ToFs8Ej7YBEjHIQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_37":{"id":"edc4671f53e1_37","__typename":"Paragraph","name":"bd67","text":"R0_rect : rotation to account for rectification for points in the reference camera.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":7,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_38":{"id":"edc4671f53e1_38","__typename":"Paragraph","name":"a608","text":"Tr_velo_to_cam : euclidean transformation from lidar to reference camera cam0 .","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":14,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":73,"end":77,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_39":{"id":"edc4671f53e1_39","__typename":"Paragraph","name":"ecc3","text":"Projection Between Frames","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_40":{"id":"edc4671f53e1_40","__typename":"Paragraph","name":"fad3","text":"Recall from linear algebra that a projection matrix, when expressed in homogenous coordinate, is simply a linear transformation that warps points through multiplication from one vector space to another vector space x’= Px. It can be composited to traverse across the different coordinate systems. I refer you to this amazing video for more explanation.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":317,"end":330,"type":"A","href":"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=XkY2DOUCWMU&t=","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":215,"end":223,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_41":{"id":"edc4671f53e1_41","__typename":"Paragraph","name":"b92a","text":"Transformation matrix in this context represents mainly the rigid body transformation between sensors and the perspective projection (collapsing column vector z) from 3D to 2D points. These matrices are given in the calibration files.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_42":{"id":"edc4671f53e1_42","__typename":"Paragraph","name":"10b7","text":"Projection from lidar to camera 2 project_velo_to_cam2: Suppose we would like to convert Velodyne points into camera coordinate, the following transformations are considered.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":34,"end":54,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":34,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":54,"end":56,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_43":{"id":"edc4671f53e1_43","__typename":"Paragraph","name":"4332","text":"proj_mat = P_rect2cam2 @ R_ref2rect @ P_velo2cam_ref","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_44":{"id":"edc4671f53e1_44","__typename":"Paragraph","name":"4832","text":"Note that the multiplication should be performed in homogenous coordinate to simplify the calculation. To convert to pixel coordinate, simply normalise by z-coordinate.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_45":{"id":"edc4671f53e1_45","__typename":"Paragraph","name":"b9ea","text":"Fig 4. Transformation steps","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*CVFRHvzg96GQ3DtbkpuHsA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_46":{"id":"edc4671f53e1_46","__typename":"Paragraph","name":"1428","text":"Projection from camera to lidar coordinate: Annotation of 3D boxes are given in camera coordinate. If we would like to convert box vertices in the camera frame to lidar, project_cam2_to_velowe compute the inverse rigid transformation and transform backwards.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":170,"end":190,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":42,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_47":{"id":"edc4671f53e1_47","__typename":"Paragraph","name":"0b4b","text":"R_ref2rect_inv = np.linalg.inv(R_ref2rect)\nP_cam_ref2velo = np.linalg.inv(velo2cam_ref)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":42,"end":43,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_48":{"id":"edc4671f53e1_48","__typename":"Paragraph","name":"3f7e","text":"proj_mat = R_ref2rect_inv @ P_cam_ref2velo","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_49":{"id":"edc4671f53e1_49","__typename":"Paragraph","name":"9800","text":"Boxes In Image","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_50":{"id":"edc4671f53e1_50","__typename":"Paragraph","name":"a0d7","text":"see render_image_with_boxes","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":4,"end":27,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_51":{"id":"edc4671f53e1_51","__typename":"Paragraph","name":"6253","text":"Boxes are commonly used to represent other agents and pedestrians. It is simpler to acquire and annotate by defining 8 vertices to fully localise the object as a box model. In my opinion, boxes might not be the best to represent pedestrians as they are not rigid.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_52":{"id":"edc4671f53e1_52","__typename":"Paragraph","name":"7e95","text":"There are some other methods to represent objects which includes key points, cad model and segmentation masks that are worth considering.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_53":{"id":"edc4671f53e1_53","__typename":"Paragraph","name":"9b0c","text":"Fig 5. Displaying boxes on the image plane","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*GFnF_pAySI2vgz_XLGgGvQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_54":{"id":"edc4671f53e1_54","__typename":"Paragraph","name":"e68c","text":"From the annotation, we are given the location of the box (t), the yaw angle (R) of the box in camera coordinates (save to assume no pitch and roll) and the dimensions: height (h), width (w) and length (l). Note that 3D boxes of objects are annotated in camera coordinate! Given this information, we can easily transform the box model to the exact location in the camera space.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":59,"end":60,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":78,"end":79,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":177,"end":178,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":188,"end":189,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":203,"end":204,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_55":{"id":"edc4671f53e1_55","__typename":"Paragraph","name":"fbf7","text":"Consider fig 5 above, each box instance origin is set to be at the base and centre, corresponding to the same height as the ego vehicle and ground level. To project 3D boxes to image:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_56":{"id":"edc4671f53e1_56","__typename":"Paragraph","name":"4079","text":"First, we obtain the box in camera coordinate via [R|t] where R = rotyand t = (tx, ty, tz) from the annotation inlabel.txt","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":62,"end":70,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":74,"end":90,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":113,"end":122,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_57":{"id":"edc4671f53e1_57","__typename":"Paragraph","name":"3abf","text":"Next, apply perspective projection to the image plane P_rect2cam2","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":54,"end":65,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_58":{"id":"edc4671f53e1_58","__typename":"Paragraph","name":"310f","text":"PointCloud in Image [3D-2D]","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_59":{"id":"edc4671f53e1_59","__typename":"Paragraph","name":"6555","text":"see render_lidar_on_image","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":4,"end":25,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_60":{"id":"edc4671f53e1_60","__typename":"Paragraph","name":"4e3c","text":"Fig 6. Colour-coded range value of Lidar points on the image","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*VzIm1rpoCtnyyXuR255hKQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_61":{"id":"edc4671f53e1_61","__typename":"Paragraph","name":"7b2a","text":"If we would like to process data in 2D, more information can be gathered by projecting point cloud onto the image to construct a sparse depth map representation using the corresponding lidar range value (z). The sparsity depends on the number of lidar beams that map to pixels.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":129,"end":145,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_62":{"id":"edc4671f53e1_62","__typename":"Paragraph","name":"14a7","text":"Sparse depth map are convenient and accurate range data as compared to predicting depth map from a camera. A work that used sparse depth map to enhance monocular based detection is described in pseudo-lidar++.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":194,"end":208,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1906.06310.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_63":{"id":"edc4671f53e1_63","__typename":"Paragraph","name":"bcb0","text":"To map points to pixel, this is a projective transformation from lidar to image plane.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_64":{"id":"edc4671f53e1_64","__typename":"Paragraph","name":"541c","text":"Compute projection matrix project_velo_to_cam2 .","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":26,"end":46,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_65":{"id":"edc4671f53e1_65","__typename":"Paragraph","name":"414d","text":"Project points to image plane.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_66":{"id":"edc4671f53e1_66","__typename":"Paragraph","name":"45ae","text":"Remove points that lie outside of image boundaries.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_67":{"id":"edc4671f53e1_67","__typename":"Paragraph","name":"24b2","text":"Boxes in PointCloud [2D-3D]","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_68":{"id":"edc4671f53e1_68","__typename":"Paragraph","name":"0b97","text":"see render_lidar_with_boxes","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":4,"end":27,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_69":{"id":"edc4671f53e1_69","__typename":"Paragraph","name":"7644","text":"Visualising and working in Lidar space provides the most comprehensive understanding in terms of spatial reasoning. Also, we can easily change our camera viewpoint to look at the environment from a different perspective if required.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_70":{"id":"edc4671f53e1_70","__typename":"Paragraph","name":"5d96","text":"Fig 7. 3D boxes projected onto point clouds","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*dSKfJ3S1aqY6w1ogWzQBSA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_71":{"id":"edc4671f53e1_71","__typename":"Paragraph","name":"29eb","text":"In this example, instead of drawing all the scanned points from the 360 deg rotated LIDAR scanner, we shall only consider point clouds that lie within the field of view of the camera as shown in fig 4. The step taken are similar to the example on points cloud in image. Next, we will need to apply the inverse transformation to project the 3D boxes in camera coordinate to LIDAR using the projection project_cam2_to_velo .","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":400,"end":420,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_72":{"id":"edc4671f53e1_72","__typename":"Paragraph","name":"b881","text":"The steps are as follows:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_73":{"id":"edc4671f53e1_73","__typename":"Paragraph","name":"386a","text":"Compute projection matrix project_velo_to_cam2 .","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":26,"end":46,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_74":{"id":"edc4671f53e1_74","__typename":"Paragraph","name":"4e46","text":"Project points to image plane.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_75":{"id":"edc4671f53e1_75","__typename":"Paragraph","name":"7e2f","text":"Remove points that lie outside of image boundaries.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_76":{"id":"edc4671f53e1_76","__typename":"Paragraph","name":"9950","text":"Project 3D boxes to LIDAR coordinate","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_77":{"id":"edc4671f53e1_77","__typename":"Paragraph","name":"d592","text":"To End Off","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_78":{"id":"edc4671f53e1_78","__typename":"Paragraph","name":"9df9","text":"Understanding how to transform data from one sensor to another is essential to develop the performance of our algorithm. For example, suppose we are working on monocular based 3D detector, lidar points provide a sanity check on the precision of our detector when registering the 3D boxes to the lidar points.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_79":{"id":"edc4671f53e1_79","__typename":"Paragraph","name":"1b67","text":"However, when it comes to sensor fusion itself, the task still remains a challenge as the multimodal sensors have several differences in the way data are stored and process as explained. This makes it difficult to align geometrically and temporally at runtime. Good calibration is essential, to begin with.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_80":{"id":"edc4671f53e1_80","__typename":"Paragraph","name":"2421","text":"Thank you for reading this article. Hope it gave you some good insights! Follow to see more post on computer vision and machine learning. If you have any questions, feel free to leave a message, private note or any feedback:)","type":"BQ","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":225,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_81":{"id":"edc4671f53e1_81","__typename":"Paragraph","name":"6b73","text":"darylclimb\u002Fcvml_project\nProjects and application using computer vision and machine learning - darylclimb\u002Fcvml_projectgithub.com","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fdarylclimb\u002Fcvml_project\u002Ftree\u002Fmaster\u002Fprojections\u002Flidar_camera_projection","thumbnailImageId":"0*E157DD0A14RKI9Yw"},"markups":[{"__typename":"Markup","start":0,"end":127,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fdarylclimb\u002Fcvml_project\u002Ftree\u002Fmaster\u002Fprojections\u002Flidar_camera_projection","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":23,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":24,"end":117,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_82":{"id":"edc4671f53e1_82","__typename":"Paragraph","name":"e28b","text":"Depth Estimation: Basics and Intuition\nUnderstanding how far things are relative to a camera remains difficult but absolutely necessary for exciting…towardsdatascience.com","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fdepth-estimation-1-basics-and-intuition-86f2c9538cd1","thumbnailImageId":"1*T2HqDxVSXO3xLjm3U-zkkA.jpeg"},"markups":[{"__typename":"Markup","start":0,"end":171,"type":"A","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fdepth-estimation-1-basics-and-intuition-86f2c9538cd1","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":38,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":39,"end":149,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:edc4671f53e1_83":{"id":"edc4671f53e1_83","__typename":"Paragraph","name":"ef8b","text":"Reference","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_84":{"id":"edc4671f53e1_84","__typename":"Paragraph","name":"373f","text":"[1] Sourabh Vora, Alex H. Lang, Bassam Helou, Oscar Beijbom. PointPainting: Sequential Fusion for 3D Object Detection, 2019","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:edc4671f53e1_85":{"id":"edc4671f53e1_85","__typename":"Paragraph","name":"61a3","text":"[2] A. Geiger, F. Moosmann, O. Car, and B. Schuster, “A toolbox for automatic calibration of range and camera sensors using a single shot,” in ICRA, 2012","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"ImageMetadata:1*-WFfHL24zz_mOZM7_blSOQ.png":{"id":"1*-WFfHL24zz_mOZM7_blSOQ.png","__typename":"ImageMetadata","originalHeight":961,"originalWidth":1281,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*BrOLss3ODN_JGUG5rI-WBw.png":{"id":"1*BrOLss3ODN_JGUG5rI-WBw.png","__typename":"ImageMetadata","originalHeight":293,"originalWidth":517,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*wMibQFL4SsSKDUkoLgi-OQ.png":{"id":"1*wMibQFL4SsSKDUkoLgi-OQ.png","__typename":"ImageMetadata","originalHeight":326,"originalWidth":391,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:0*rRWRXHIHP2YvrUYU.jpg":{"id":"0*rRWRXHIHP2YvrUYU.jpg","__typename":"ImageMetadata","originalHeight":1161,"originalWidth":2600,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*xhwMXO8ToFs8Ej7YBEjHIQ.png":{"id":"1*xhwMXO8ToFs8Ej7YBEjHIQ.png","__typename":"ImageMetadata","originalHeight":118,"originalWidth":356,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*CVFRHvzg96GQ3DtbkpuHsA.png":{"id":"1*CVFRHvzg96GQ3DtbkpuHsA.png","__typename":"ImageMetadata","originalHeight":211,"originalWidth":406,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*GFnF_pAySI2vgz_XLGgGvQ.png":{"id":"1*GFnF_pAySI2vgz_XLGgGvQ.png","__typename":"ImageMetadata","originalHeight":559,"originalWidth":914,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*VzIm1rpoCtnyyXuR255hKQ.png":{"id":"1*VzIm1rpoCtnyyXuR255hKQ.png","__typename":"ImageMetadata","originalHeight":375,"originalWidth":1242,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*dSKfJ3S1aqY6w1ogWzQBSA.png":{"id":"1*dSKfJ3S1aqY6w1ogWzQBSA.png","__typename":"ImageMetadata","originalHeight":1244,"originalWidth":2804,"focusPercentX":null,"focusPercentY":null,"alt":null},"Tag:machine-learning":{"id":"machine-learning","__typename":"Tag","displayTitle":"Machine Learning"},"Tag:python":{"id":"python","__typename":"Tag","displayTitle":"Python"},"Tag:computer-vision":{"id":"computer-vision","__typename":"Tag","displayTitle":"Computer Vision"},"Tag:autonomous-vehicles":{"id":"autonomous-vehicles","__typename":"Tag","displayTitle":"Autonomous Vehicles"},"Tag:robotics":{"id":"robotics","__typename":"Tag","displayTitle":"Robotics"},"ImageMetadata:1*J9SQ1JdVMe1pSB-jePs1zg.jpeg":{"id":"1*J9SQ1JdVMe1pSB-jePs1zg.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:51879ac498f2":{"id":"51879ac498f2","__typename":"User","name":"Uday Marepalli","username":"uday.marepalli","bio":"At the intersection of technology, startups and business.","isFollowing":null,"imageId":"1*2Os7tI5ZmJzI6h_7tTZ0sw.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:9111b2e233f6":{"id":"9111b2e233f6","__typename":"Post","title":"A 3 step guide to assess any business use-case of AI","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fa-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6","previewImage":{"__ref":"ImageMetadata:1*J9SQ1JdVMe1pSB-jePs1zg.jpeg"},"isPublished":true,"firstPublishedAt":1546517542989,"readingTime":8.973584905660378,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:f5af2b715248"},"creator":{"__ref":"User:51879ac498f2"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*jdUbWGwyIyJJ4wlr1FaSqA.png":{"id":"1*jdUbWGwyIyJJ4wlr1FaSqA.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"Collection:53c7c27702d5":{"id":"53c7c27702d5","__typename":"Collection","name":"Airbnb Engineering & Data Science","slug":"airbnb-engineering","domain":null},"User:c00b242128fe":{"id":"c00b242128fe","__typename":"User","name":"Robert Chang","username":"rchang","bio":"Data @Airbnb, previously @Twitter. Opinions are my own.","isFollowing":null,"imageId":"1*EguVA0HsIGqUy0gaDS1VgA.png","mediumMemberAt":0,"hasDomain":false},"Post:9272d3d4739d":{"id":"9272d3d4739d","__typename":"Post","title":"Using Machine Learning to Predict Value of Homes On Airbnb","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fairbnb-engineering\u002Fusing-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d","previewImage":{"__ref":"ImageMetadata:1*jdUbWGwyIyJJ4wlr1FaSqA.png"},"isPublished":true,"firstPublishedAt":1500303661667,"readingTime":8.725471698113207,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:53c7c27702d5"},"creator":{"__ref":"User:c00b242128fe"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*6gGuWfqcyBFT2_h-vIaXpA.jpeg":{"id":"1*6gGuWfqcyBFT2_h-vIaXpA.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:ebad1457e228":{"id":"ebad1457e228","__typename":"User","name":"Van Phan","username":"673","bio":"","isFollowing":null,"imageId":"0*hz_uOAbWjds12L3S.jpg","mediumMemberAt":0,"hasDomain":false},"Post:93238633447e":{"id":"93238633447e","__typename":"Post","title":"Machine Learning: from human imagination to real life","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@673\u002Fmachine-learning-from-human-imagination-to-real-life-93238633447e","previewImage":{"__ref":"ImageMetadata:1*6gGuWfqcyBFT2_h-vIaXpA.jpeg"},"isPublished":true,"firstPublishedAt":1561532065414,"readingTime":9.355974842767296,"statusForCollection":null,"isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:ebad1457e228"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*JgRLAbBUxzaigOAkkdkLYQ.png":{"id":"1*JgRLAbBUxzaigOAkkdkLYQ.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"Collection:3db3a67cb648":{"id":"3db3a67cb648","__typename":"Collection","name":"Capital One Tech","slug":"capital-one-tech","domain":null},"User:102fa5d476a4":{"id":"102fa5d476a4","__typename":"User","name":"Jeremy Goodsitt","username":"jeremygoodsitt","bio":"I’m a Senior Data engineer at Capital One working on synthetic data, hyperparameter optimization and AutoML techniques.","isFollowing":null,"imageId":"0*lDon41zI9PQpurcs.","mediumMemberAt":0,"hasDomain":false},"Post:92d9f9add416":{"id":"92d9f9add416","__typename":"Post","title":"System & Language Agnostic Hyperparameter Optimization at Scale","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fcapital-one-tech\u002Fsystem-language-agnostic-hyperparameter-optimization-at-scale-and-its-importance-for-automl-92d9f9add416","previewImage":{"__ref":"ImageMetadata:1*JgRLAbBUxzaigOAkkdkLYQ.png"},"isPublished":true,"firstPublishedAt":1553601961105,"readingTime":5.988050314465409,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:3db3a67cb648"},"creator":{"__ref":"User:102fa5d476a4"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*A0qSZq1aE8w42YZg":{"id":"0*A0qSZq1aE8w42YZg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:c867c0804e76":{"id":"c867c0804e76","__typename":"User","name":"Severin Perez","username":"severinperez","bio":"Writer | Developer","isFollowing":null,"imageId":"1*QsVxhN14jwpYx3RDoLR5bA.jpeg","mediumMemberAt":1526964813000,"hasDomain":false},"Post:927d5b6556bf":{"id":"927d5b6556bf","__typename":"Post","title":"Exploring Literature with the Stanza NLP Package","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@severinperez\u002Fexploring-literature-with-the-stanza-nlp-package-927d5b6556bf","previewImage":{"__ref":"ImageMetadata:0*A0qSZq1aE8w42YZg"},"isPublished":true,"firstPublishedAt":1598307337082,"readingTime":4.033962264150944,"statusForCollection":null,"isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:c867c0804e76"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*f0cx1ECtYBHpP5FSQGPHXA.jpeg":{"id":"1*f0cx1ECtYBHpP5FSQGPHXA.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"Collection:7219b4dc6c4c":{"id":"7219b4dc6c4c","__typename":"Collection","name":"Analytics Vidhya","slug":"analytics-vidhya","domain":null},"User:7b6def524575":{"id":"7b6def524575","__typename":"User","name":"Soumya Gupta","username":"soumyansh","bio":"A castaway coder , I love to play with Data.","isFollowing":null,"imageId":"2*mkG_FoyKM0eZlVKJY2AklA.png","mediumMemberAt":0,"hasDomain":false},"Post:93b76ab6348c":{"id":"93b76ab6348c","__typename":"Post","title":"Embedding Sentiment Analysis Model into a Web Application","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fembedding-sentiment-analysis-model-into-a-web-application-93b76ab6348c","previewImage":{"__ref":"ImageMetadata:1*f0cx1ECtYBHpP5FSQGPHXA.jpeg"},"isPublished":true,"firstPublishedAt":1578142419924,"readingTime":9.619811320754717,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7219b4dc6c4c"},"creator":{"__ref":"User:7b6def524575"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*BqOmPcklT4b32YcKEmz3pg.png":{"id":"1*BqOmPcklT4b32YcKEmz3pg.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:f9f914e94fe0":{"id":"f9f914e94fe0","__typename":"User","name":"Bill Huang","username":"yingbiao","bio":"Finding beauty in texts:)","isFollowing":null,"imageId":"1*-7jbB1rHfqL1AP54yvaJkA.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:936ff275bc73":{"id":"936ff275bc73","__typename":"Post","title":"NER with BERT in Action","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@yingbiao\u002Fner-with-bert-in-action-936ff275bc73","previewImage":{"__ref":"ImageMetadata:1*BqOmPcklT4b32YcKEmz3pg.png"},"isPublished":true,"firstPublishedAt":1564505048818,"readingTime":4.7493710691823905,"statusForCollection":null,"isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:f9f914e94fe0"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*wQKLVH7-p7ZTylHXfp-gIw.png":{"id":"1*wQKLVH7-p7ZTylHXfp-gIw.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:c1a2f04ad037":{"id":"c1a2f04ad037","__typename":"User","name":"Daniele Pestilli","username":"DaniG2k","bio":"Full-stack developer, East Asia enthusiast, Artist","isFollowing":null,"imageId":"1*P23tyhXr4yDkM8KqZwedXQ.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:9344085f0386":{"id":"9344085f0386","__typename":"Post","title":"Inside the Neural Network — a brief introduction","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@DaniG2k\u002Finside-the-neural-network-a-brief-introduction-9344085f0386","previewImage":{"__ref":"ImageMetadata:1*wQKLVH7-p7ZTylHXfp-gIw.png"},"isPublished":true,"firstPublishedAt":1559415618178,"readingTime":11.102830188679246,"statusForCollection":null,"isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:c1a2f04ad037"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"Post:911c78167a94":{"id":"911c78167a94","__typename":"Post","canonicalUrl":"","collection":{"__ref":"Collection:f5af2b715248"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:edc4671f53e1_0"},{"__ref":"Paragraph:edc4671f53e1_1"},{"__ref":"Paragraph:edc4671f53e1_2"},{"__ref":"Paragraph:edc4671f53e1_3"},{"__ref":"Paragraph:edc4671f53e1_4"},{"__ref":"Paragraph:edc4671f53e1_5"},{"__ref":"Paragraph:edc4671f53e1_6"},{"__ref":"Paragraph:edc4671f53e1_7"},{"__ref":"Paragraph:edc4671f53e1_8"},{"__ref":"Paragraph:edc4671f53e1_9"},{"__ref":"Paragraph:edc4671f53e1_10"},{"__ref":"Paragraph:edc4671f53e1_11"},{"__ref":"Paragraph:edc4671f53e1_12"},{"__ref":"Paragraph:edc4671f53e1_13"},{"__ref":"Paragraph:edc4671f53e1_14"},{"__ref":"Paragraph:edc4671f53e1_15"},{"__ref":"Paragraph:edc4671f53e1_16"},{"__ref":"Paragraph:edc4671f53e1_17"},{"__ref":"Paragraph:edc4671f53e1_18"},{"__ref":"Paragraph:edc4671f53e1_19"},{"__ref":"Paragraph:edc4671f53e1_20"},{"__ref":"Paragraph:edc4671f53e1_21"},{"__ref":"Paragraph:edc4671f53e1_22"},{"__ref":"Paragraph:edc4671f53e1_23"},{"__ref":"Paragraph:edc4671f53e1_24"},{"__ref":"Paragraph:edc4671f53e1_25"},{"__ref":"Paragraph:edc4671f53e1_26"},{"__ref":"Paragraph:edc4671f53e1_27"},{"__ref":"Paragraph:edc4671f53e1_28"},{"__ref":"Paragraph:edc4671f53e1_29"},{"__ref":"Paragraph:edc4671f53e1_30"},{"__ref":"Paragraph:edc4671f53e1_31"},{"__ref":"Paragraph:edc4671f53e1_32"},{"__ref":"Paragraph:edc4671f53e1_33"},{"__ref":"Paragraph:edc4671f53e1_34"},{"__ref":"Paragraph:edc4671f53e1_35"},{"__ref":"Paragraph:edc4671f53e1_36"},{"__ref":"Paragraph:edc4671f53e1_37"},{"__ref":"Paragraph:edc4671f53e1_38"},{"__ref":"Paragraph:edc4671f53e1_39"},{"__ref":"Paragraph:edc4671f53e1_40"},{"__ref":"Paragraph:edc4671f53e1_41"},{"__ref":"Paragraph:edc4671f53e1_42"},{"__ref":"Paragraph:edc4671f53e1_43"},{"__ref":"Paragraph:edc4671f53e1_44"},{"__ref":"Paragraph:edc4671f53e1_45"},{"__ref":"Paragraph:edc4671f53e1_46"},{"__ref":"Paragraph:edc4671f53e1_47"},{"__ref":"Paragraph:edc4671f53e1_48"},{"__ref":"Paragraph:edc4671f53e1_49"},{"__ref":"Paragraph:edc4671f53e1_50"},{"__ref":"Paragraph:edc4671f53e1_51"},{"__ref":"Paragraph:edc4671f53e1_52"},{"__ref":"Paragraph:edc4671f53e1_53"},{"__ref":"Paragraph:edc4671f53e1_54"},{"__ref":"Paragraph:edc4671f53e1_55"},{"__ref":"Paragraph:edc4671f53e1_56"},{"__ref":"Paragraph:edc4671f53e1_57"},{"__ref":"Paragraph:edc4671f53e1_58"},{"__ref":"Paragraph:edc4671f53e1_59"},{"__ref":"Paragraph:edc4671f53e1_60"},{"__ref":"Paragraph:edc4671f53e1_61"},{"__ref":"Paragraph:edc4671f53e1_62"},{"__ref":"Paragraph:edc4671f53e1_63"},{"__ref":"Paragraph:edc4671f53e1_64"},{"__ref":"Paragraph:edc4671f53e1_65"},{"__ref":"Paragraph:edc4671f53e1_66"},{"__ref":"Paragraph:edc4671f53e1_67"},{"__ref":"Paragraph:edc4671f53e1_68"},{"__ref":"Paragraph:edc4671f53e1_69"},{"__ref":"Paragraph:edc4671f53e1_70"},{"__ref":"Paragraph:edc4671f53e1_71"},{"__ref":"Paragraph:edc4671f53e1_72"},{"__ref":"Paragraph:edc4671f53e1_73"},{"__ref":"Paragraph:edc4671f53e1_74"},{"__ref":"Paragraph:edc4671f53e1_75"},{"__ref":"Paragraph:edc4671f53e1_76"},{"__ref":"Paragraph:edc4671f53e1_77"},{"__ref":"Paragraph:edc4671f53e1_78"},{"__ref":"Paragraph:edc4671f53e1_79"},{"__ref":"Paragraph:edc4671f53e1_80"},{"__ref":"Paragraph:edc4671f53e1_81"},{"__ref":"Paragraph:edc4671f53e1_82"},{"__ref":"Paragraph:edc4671f53e1_83"},{"__ref":"Paragraph:edc4671f53e1_84"},{"__ref":"Paragraph:edc4671f53e1_85"}],"sections":[{"__typename":"Section","name":"811c","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"5ba4","startIndex":81,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"a233","startIndex":82,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"creator":{"__ref":"User:d5d47d10c0e9"},"customStyleSheet":null,"firstPublishedAt":1580401909422,"isLocked":true,"isPublished":true,"isShortform":false,"isEmail":false,"layerCake":3,"primaryTopic":{"__typename":"Topic","name":"Machine Learning","slug":"machine-learning","isFollowing":null},"title":"Camera-Lidar Projection: Navigating between 2D and 3D","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94","isLimitedState":false,"visibility":"LOCKED","license":"ALL_RIGHTS_RESERVED","allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:machine-learning"},{"__ref":"Tag:python"},{"__ref":"Tag:computer-vision"},{"__ref":"Tag:autonomous-vehicles"},{"__ref":"Tag:robotics"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning","slug":"machine-learning"}],"viewerClapCount":0,"inResponseToPostResult":null,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1602896995489,"readingTime":7.528301886792453,"previewContent":{"__typename":"PreviewContent","subtitle":"Lidars and cameras are two essential sensors for perception and scene understanding. They build an environment in tandem and provide a…"},"previewImage":{"__ref":"ImageMetadata:1*-WFfHL24zz_mOZM7_blSOQ.png"},"creatorPartnerProgramEnrollmentStatus":"PERMISSION_DENIED","clapCount":336,"lockedSource":"LOCKED_POST_SOURCE_UGC","isSuspended":false,"nextPostId":"9111b2e233f6","pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"pinnedByCreatorAt":0,"responsesCount":0,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:9111b2e233f6"},{"__ref":"Post:9272d3d4739d"},{"__ref":"Post:93238633447e"},{"__ref":"Post:92d9f9add416"},{"__ref":"Post:927d5b6556bf"},{"__ref":"Post:93b76ab6348c"},{"__ref":"Post:936ff275bc73"},{"__ref":"Post:9344085f0386"}]},"collaborators":[],"translationSourcePost":null,"inResponseToMediaResource":null,"curationEligibleAt":0,"isDistributionAlertDismissed":false,"audioVersionUrl":"","seoTitle":"","updatedAt":1602897006520,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","postResponses":{"__typename":"PostResponses","count":0},"latestPublishedVersion":"edc4671f53e1","readingList":"READING_LIST_NONE","voterCount":76,"recommenders":[],"shareKey":null}}</script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/manifest.ca6c97ed.js"></script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_main.dcfe56d4.chunk.js"></script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/main.39cf8597.chunk.js"></script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_instrumentation.7f992f90.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/instrumentation.acd8fd3c.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/reporting.ffa3aeeb.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_AMPPost_CollectionAbout_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformE_74d53cd4.ee0a8adb.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionStyleEditor_CollectionTagged__42f7530a.0dd746e8.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/vendors_AMPPost_CollectionNewShortformEditor_CollectionPostShortformEditor_DebugCachedPost_Post_Sequ_19f09bd3.1bf7a765.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_CollectionPostShor_250d4f3e.3840d390.chunk.js"></script>
<script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/Post.b333ab44.chunk.js"></script><script>window.main();</script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/p.js" async="" id="parsely-cf"></script><script src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/client" async=""></script><div id="credential_picker_container" style="position: fixed; z-index: 9999; height: 204px;"><iframe src="./Camera-Lidar Projection_ Navigating between 2D and 3D _ by Daryl Tan _ The Startup _ Medium_files/select.html" style="height: 204px; width: 391px; overflow: hidden;"></iframe></div></body></html>